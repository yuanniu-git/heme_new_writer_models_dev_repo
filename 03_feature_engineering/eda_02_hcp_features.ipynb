{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523d8ba2-6fc0-4977-a300-77d08baedd1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00_config/set-up\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c10a8d28-00ca-43a1-b772-01ce7a652515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16470f5f-6ea0-4d97-b760-a495b42bb67f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM heme_data.overlap_rx\")\n",
    "print('Row count: ', df.count(), 'Column Count: ', len(df.columns))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a2c32cc-5357-4c60-af04-34bcfdbc0599",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Diagnostics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee3ef335-0ce8-47fb-b74c-8ab3a3079593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "# unique patients, hcps, and unique patients by PTNT_AGE_GRP\n",
    "unique_counts = df.agg(\n",
    "    countDistinct(\"PATIENT_ID\").alias(\"unique_patients\"),\n",
    "    countDistinct(\"BH_ID\").alias(\"unique_hcps\")\n",
    ")\n",
    "\n",
    "unique_patients_by_age_grp = df.groupBy(\"PTNT_AGE_GRP\").agg(\n",
    "    countDistinct(\"PATIENT_ID\").alias(\"unique_patients\")\n",
    ")\n",
    "\n",
    "# count of patients in 2023\n",
    "patients_2023_count = df.filter(year(\"SHP_DT\") == 2023).agg(\n",
    "    countDistinct(\"PATIENT_ID\").alias(\"patients_2023\")\n",
    ")\n",
    "\n",
    "unique_counts.display()\n",
    "unique_patients_by_age_grp.display()\n",
    "patients_2023_count.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d06e4de-ce38-47c8-aa48-70fda605a908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Patients with multiple BRTH_YR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3542efb2-a8f1-4ec2-ad6b-39940afec399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Patients with inconsistent BRTH_YR btween SHS and SP\n",
    "# Filter rows where both SP_PTNT_BRTH_YR and SHS_PTNT_BRTH_YR are not null and their values are different\n",
    "df_filtered = df.filter(\n",
    "    (col(\"SP_PTNT_BRTH_YR\").isNotNull()) &\n",
    "    (col(\"SHS_PTNT_BRTH_YR\").isNotNull()) &\n",
    "    (col(\"SP_PTNT_BRTH_YR\") != col(\"SHS_PTNT_BRTH_YR\"))\n",
    ")\n",
    "\n",
    "# Count the number of unique patients with the problem\n",
    "problem_patient_count = df_filtered.select(\"PATIENT_ID\").distinct().count()\n",
    "\n",
    "# Find the patients with the most number of records with different non-null values\n",
    "patient_record_counts = df_filtered.groupBy(\"PATIENT_ID\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# Get the patient(s) with the most number of records\n",
    "max_record_count = patient_record_counts.first()[\"count\"]\n",
    "patients_with_max_records = patient_record_counts.filter(col(\"count\") == max_record_count).select(\"PATIENT_ID\")\n",
    "\n",
    "# Show records for the patients who have the most number of records with different non-null values\n",
    "df_problem_patients = df_filtered.join(patients_with_max_records, on=\"PATIENT_ID\")\n",
    "\n",
    "# Display results\n",
    "print(f\"Number of patients with the problem: {problem_patient_count}\")\n",
    "df_problem_patients.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d75e8ec7-7367-42fc-b2a1-5202bd43c660",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of unique PATIENT_ID that have multiple not null BRTH_YR values\n",
    "\n",
    "# Filter rows where BRTH_YR is not null\n",
    "df_filtered = df.filter(col(\"BRTH_YR\").isNotNull())\n",
    "\n",
    "# Select PATIENT_ID where BRTH_YR column has multiple values\n",
    "df_multiple_brth_yr = df_filtered.groupBy(\"PATIENT_ID\").agg(\n",
    "    countDistinct(\"BRTH_YR\").alias(\"distinct_brth_yr_count\")\n",
    ").filter(col(\"distinct_brth_yr_count\") > 1).select(\"PATIENT_ID\")\n",
    "\n",
    "# Count the number of unique PATIENT_IDs with multiple BRTH_YR values\n",
    "patient_count = df_multiple_brth_yr.distinct().count()\n",
    "\n",
    "# Display results\n",
    "print(f\"Number of patients with multiple BRTH_YR values: {patient_count}\")\n",
    "df_multiple_brth_yr.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d427edab-775c-4b86-8489-e0e1ba7ca09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Calculate Weekly IUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6079f8bd-3b67-44fe-b788-cc36a6e141a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summarize IU by patient, product, week\n",
    "from pyspark.sql.functions import date_trunc, to_date\n",
    "\n",
    "# derive week from date\n",
    "columns = ['BH_ID', 'PATIENT_ID', 'PRD_NM', 'SHP_DT', 'PRPHY', 'IU']\n",
    "df_selected = df.select(*columns)\n",
    "df_with_week = df_selected.withColumn(\n",
    "    \"SHP_WK\",\n",
    "    to_date(date_trunc(\"week\", F.col(\"SHP_DT\")))\n",
    ")\n",
    "\n",
    "# calculate weekly IU\n",
    "df_iu = df_with_week.filter(F.col(\"PRD_NM\").isNotNull()).groupBy(\n",
    "    \"BH_ID\",\n",
    "    \"PATIENT_ID\",\n",
    "    \"PRD_NM\",\n",
    "    \"PRPHY\",\n",
    "    \"SHP_WK\"\n",
    ").agg(\n",
    "    F.sum(\"IU\").alias(\"IU\")\n",
    ").withColumn('PRPHY', F.coalesce(F.col('PRPHY'), F.lit('1'))) \\\n",
    ".orderBy(F.col('PATIENT_ID').desc(), F.col('PRD_NM').desc(), F.col('SHP_WK').asc())\n",
    "\n",
    "df_iu.printSchema()\n",
    "df_iu.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9a9d260-ce3d-433f-af2c-fe5b52c6fc61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create Product_Prophy column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a8e515d-c8a7-42fc-b0f9-8676504729f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Create PRD_PRPHY\n",
    "# 1. Create the new column PRD_PRPHY by combining PRD_NM and PRPHY\n",
    "df_iu_2 = df_iu.withColumn(\n",
    "    \"PRD_PRPHY\",\n",
    "    concat(col(\"PRD_NM\"), lit(\"_\"), col(\"PRPHY\"))\n",
    ")\n",
    "\n",
    "## Create WK_SINCE_LST_SHP\n",
    "# 2. Define a window specification\n",
    "window_spec = Window.partitionBy(\"BH_ID\", \"PATIENT_ID\").orderBy(\"SHP_WK\")\n",
    "\n",
    "# 3. Calculate the previous SHP_WK date\n",
    "df_iu_3 = df_iu_2.withColumn(\"PREV_SHP_WK\", \n",
    "                                        expr(\"lag(SHP_WK) over (partition by BH_ID, PATIENT_ID order by SHP_WK)\"))\n",
    "\n",
    "# 4. Calculate the number of weeks since the last shipment\n",
    "df_iu_4 = df_iu_3.withColumn(\n",
    "    \"WK_SINCE_LST_SHP\",\n",
    "    (datediff(col(\"SHP_WK\"), col(\"PREV_SHP_WK\")) / 7).cast(\"integer\")\n",
    ").fillna(0)\n",
    "# Show the updated DataFrame\n",
    "df_iu_4.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b5f6002-4b59-4916-8bd0-e6a9064c712e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select the columns\n",
    "selected_columns_df = df_iu_4.select(\"BH_ID\", \"PATIENT_ID\", \"PRD_PRPHY\", \"WK_SINCE_LST_SHP\")\n",
    "\n",
    "# Group by BH_ID and PATIENT_ID and aggregate PRD_PRPHY\n",
    "df_iu_5 = selected_columns_df.groupBy(\"BH_ID\", \"PATIENT_ID\") \\\n",
    "    .agg(\n",
    "        concat_ws(\", \", collect_list(\"PRD_PRPHY\")).alias(\"PRD_PRPHY_ALL\"),\n",
    "        # You can also aggregate WK_SINCE_LST_SHP if needed, for example, using max or sum\n",
    "        # Here we will take the maximum WK_SINCE_LST_SHP for demonstration\n",
    "        # max(\"WK_SINCE_LST_SHP\").alias(\"WK_SINCE_LST_SHP\")\n",
    "    )\n",
    "\n",
    "# result DataFrame\n",
    "df_iu_5.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9daa91c1-68ac-4522-a2e2-3d11b4d4db3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Show HCP's Rx history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6692792-2774-449e-8570-2d7d0081841c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_iu_5.filter(col('BH_ID') == 'BH10200613').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ad628fc-29d4-4387-af61-ddf35507bb9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Patients who used JIVI\n",
    "df_iu_jivi = df_iu_5.filter(col(\"PRD_PRPHY_ALL\").contains(\"JIVI\"))\n",
    "df_iu_jivi.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19504c70-92e5-49a5-849f-df80f2a7e414",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"unique BH_ID:\", df_iu_jivi.select(\"BH_ID\").distinct().count())\n",
    "print(\"unique PATIENT_ID:\", df_iu_jivi.select(\"PATIENT_ID\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5720a90a-1ba9-4a1f-a433-efe099eb6507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# All PRD_PRPHY records for JIVI patients\n",
    "# Select relevant columns from df_iu_5\n",
    "df_iu_5_selected = df_iu_5.select(\"BH_ID\", \"PATIENT_ID\", \"PRD_PRPHY_ALL\")\n",
    "\n",
    "# Step 2: Create a new DataFrame df_iu_jivi_pt by joining df_iu_jivi with df_iu_5\n",
    "df_iu_jivi_pt = df_iu_jivi.alias(\"jivi\").join(\n",
    "    df_iu_5_selected.alias(\"iu_5\"),\n",
    "    on=\"PATIENT_ID\",\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    \"iu_5.BH_ID\",\n",
    "    \"jivi.PATIENT_ID\",\n",
    "    \"iu_5.PRD_PRPHY_ALL\"\n",
    ")\n",
    "\n",
    "# Step 3: Show the resulting DataFrame\n",
    "display(df_iu_jivi_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ce23bc-df93-4cc9-a65a-2a2569cf3df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"unique BH_ID:\", df_iu_jivi_pt.select(\"BH_ID\").distinct().count())\n",
    "print(\"unique PATIENT_ID:\", df_iu_jivi_pt.select(\"PATIENT_ID\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43cde903-320b-4bdf-b8c3-5d3c1f9699c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "eda_02_hcp_features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
