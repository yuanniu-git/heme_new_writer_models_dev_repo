{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb7944c-e4c3-4839-93fd-8f1022a025e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training binary classification model for Jivi restart writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c584d628-9c9e-42de-9d00-059ff18d4dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb8e736-30ce-4eaf-b8e9-eeee60a68ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04e44c0d-119f-4310-ae0a-729946c0a1cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563d5487-0e02-48ad-b4d8-4430c5d76991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, \n",
    "    f1_score, precision_recall_curve, auc\n",
    ")\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cf81b8-0210-4341-8583-eb34f215a918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00_config/set-up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "287c301a-8239-4b62-a664-76bcbe38cfda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Month and Date parameters for manual control\n",
    "first_month = \"2019-12\"\n",
    "last_month = \"2024-11\"\n",
    "\n",
    "train_start_month = \"2023-01\"\n",
    "train_end_month = \"2024-04\"\n",
    "test_start_month = \"2024-05\"\n",
    "test_end_month = \"2024-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0bbca16-6d71-49c9-a460-e10cd2767ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading the feature master table from Hivestore\n",
    "hcp_feats_master_w_target_sdf = spark.sql(\"SELECT * FROM jivi_new_writer_model.hcp_feats_master_w_target\")\n",
    "print(\n",
    "    \"Row count: \",\n",
    "    hcp_feats_master_w_target_sdf.count(),\n",
    "    \"Column Count: \",\n",
    "    len(hcp_feats_master_w_target_sdf.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbded0fe-6ffb-4101-b743-596ade038d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Converting Spark dataframe to Pandas dataframe\n",
    "hcp_feats_master_w_target_pdf = hcp_feats_master_w_target_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ca94fc-1c5f-400c-83a8-9a9f4aaee2ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feat_cols_nm_lst = [col for col in hcp_feats_master_w_target_pdf.columns if col not in ['BH_ID', 'COHORT_MONTH', 'JIVI_NEW_WRITER_FLG']]\n",
    "target_col_nm = 'JIVI_NEW_WRITER_FLG'\n",
    "print(\"Names of feats\", feat_cols_nm_lst)\n",
    "print(\"Number of features: \", len(feat_cols_nm_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13a0f8c3-ed1b-4176-9b27-f7e71476c813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    feature_cols: List[str],\n",
    "    train_end_month: str,\n",
    "    scale: bool = False\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepare data for training and testing based on COHORT_MONTH.\n",
    "    \n",
    "    Args:\n",
    "        df: Input Pandas DataFrame\n",
    "        target_col: Name of target column\n",
    "        feature_cols: List of feature column names\n",
    "        train_end_month: End month for training data (YYYY-MM format)\n",
    "        scale: Whether to apply StandardScaler to the features\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test as Pandas DataFrames/Series\n",
    "    \"\"\"\n",
    "    # Ensure input is a pandas DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    # Split data into train and test\n",
    "    train_mask = pd.to_datetime(df['COHORT_MONTH']).dt.strftime('%Y-%m') <= train_end_month\n",
    "    \n",
    "    # Create train/test splits using pandas\n",
    "    X_train = df[train_mask][feature_cols]\n",
    "    X_test = df[~train_mask][feature_cols]\n",
    "    y_train = df[train_mask][target_col]\n",
    "    y_test = df[~train_mask][target_col]\n",
    "    \n",
    "    # Scale features if scale is True\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = pd.DataFrame(\n",
    "            scaler.fit_transform(X_train),\n",
    "            columns=feature_cols,\n",
    "            index=X_train.index\n",
    "        )\n",
    "        X_test = pd.DataFrame(\n",
    "            scaler.transform(X_test),\n",
    "            columns=feature_cols,\n",
    "            index=X_test.index\n",
    "        )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec62446-0c77-41e0-b662-57cabaa6d1fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def select_features(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    feature_cols: List[str],\n",
    "    method: str = None,\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Perform feature selection using either Random Forest or RFE.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features DataFrame\n",
    "        y_train: Training target Series\n",
    "        feature_cols: List of feature names\n",
    "        method: Feature selection method ('rf' or 'rfe')\n",
    "    \n",
    "    Returns:\n",
    "        Selected X_train DataFrame and list of selected feature names\n",
    "    \"\"\"\n",
    "    # Get number of features using Python's built-in len\n",
    "    n_features = len(X_train.columns)\n",
    "    # Use Python's built-in min function with a list\n",
    "    max_features = 50 if n_features > 50 else n_features\n",
    "    \n",
    "    if method == 'rf':\n",
    "        selector = SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            max_features=max_features\n",
    "        )\n",
    "    else:\n",
    "        selector = RFE(\n",
    "            estimator=LogisticRegression(random_state=42),\n",
    "            n_features_to_select=max_features\n",
    "        )\n",
    "    \n",
    "    # Fit selector\n",
    "    selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = [\n",
    "        feature_name for feature_name, selected \n",
    "        in zip(feature_cols, selector.get_support())\n",
    "        if selected\n",
    "    ]\n",
    "    \n",
    "    # Return selected features DataFrame\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    \n",
    "    return X_train_selected, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d298025-20b9-437a-9d4e-fe4bf372a7db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_time_series_cv(\n",
    "    X: pd.DataFrame,\n",
    "    n_splits: int = 7 # equal to number of training months\n",
    ") -> TimeSeriesSplit:\n",
    "    \"\"\"\n",
    "    Create time series cross-validation splits.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature DataFrame\n",
    "        n_splits: Number of splits for cross-validation\n",
    "    \n",
    "    Returns:\n",
    "        TimeSeriesSplit object\n",
    "    \"\"\"\n",
    "    return TimeSeriesSplit(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee72e389-73b6-495a-922c-0af84c24e392",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_evaluate_model(\n",
    "    model: Any,\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    cv: TimeSeriesSplit\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Train model and evaluate performance using multiple metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: ML model instance\n",
    "        X_train, X_test: Training and test DataFrames\n",
    "        y_train, y_test: Training and test Series\n",
    "        cv: Cross-validation splitter\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'auc_roc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    # Calculate PR AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    metrics['auc_pr'] = auc(recall, precision)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b78cb8a7-a401-4f74-9e2f-b1fb02775bac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(\n",
    "    model: Any,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    cv: TimeSeriesSplit\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot learning curves for the model.\n",
    "    \n",
    "    Args:\n",
    "        model: ML model instance\n",
    "        X_train: Training features DataFrame\n",
    "        y_train: Training target Series\n",
    "        cv: Cross-validation splitter\n",
    "    \"\"\"\n",
    "    train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "    train_scores_list = []\n",
    "    val_scores_list = []\n",
    "    \n",
    "    # Convert train_sizes to actual numbers of samples\n",
    "    n_samples = len(X_train)\n",
    "    train_sizes_abs = [int(n * n_samples) for n in train_sizes]\n",
    "    \n",
    "    # For each CV split\n",
    "    for train_idx, val_idx in cv.split(X_train):\n",
    "        X_train_cv = X_train.iloc[train_idx]\n",
    "        X_val_cv = X_train.iloc[val_idx]\n",
    "        y_train_cv = y_train.iloc[train_idx]\n",
    "        y_val_cv = y_train.iloc[val_idx]\n",
    "        \n",
    "        train_scores_split = []\n",
    "        val_scores_split = []\n",
    "        \n",
    "        # For each training size\n",
    "        for train_size in train_sizes_abs:\n",
    "            # Fit model on subset of training data\n",
    "            model_clone = clone(model)  # Create a fresh clone of the model\n",
    "            X_subset = X_train_cv.iloc[:train_size]\n",
    "            y_subset = y_train_cv.iloc[:train_size]\n",
    "            \n",
    "            model_clone.fit(X_subset, y_subset)\n",
    "            \n",
    "            # Calculate scores\n",
    "            train_score = model_clone.score(X_subset, y_subset)\n",
    "            val_score = model_clone.score(X_val_cv, y_val_cv)\n",
    "            \n",
    "            train_scores_split.append(train_score)\n",
    "            val_scores_split.append(val_score)\n",
    "        \n",
    "        train_scores_list.append(train_scores_split)\n",
    "        val_scores_list.append(val_scores_split)\n",
    "    \n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    train_scores = np.array(train_scores_list)\n",
    "    val_scores = np.array(val_scores_list)\n",
    "    \n",
    "    # Calculate means and standard deviations\n",
    "    train_mean = np.mean(train_scores, axis=0)\n",
    "    train_std = np.std(train_scores, axis=0)\n",
    "    val_mean = np.mean(val_scores, axis=0)\n",
    "    val_std = np.std(val_scores, axis=0)\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.grid()\n",
    "    \n",
    "    # Plot training scores\n",
    "    plt.fill_between(train_sizes, \n",
    "                    train_mean - train_std,\n",
    "                    train_mean + train_std, \n",
    "                    alpha=0.1,\n",
    "                    color=\"r\")\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    \n",
    "    # Plot cross-validation scores\n",
    "    plt.fill_between(train_sizes, \n",
    "                    val_mean - val_std,\n",
    "                    val_mean + val_std, \n",
    "                    alpha=0.1, \n",
    "                    color=\"g\")\n",
    "    plt.plot(train_sizes, val_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    \n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f15a30a-5584-45a8-a87f-6b350ff5828c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analyze_feature_importance(\n",
    "    model: Any,\n",
    "    X_train: pd.DataFrame,\n",
    "    feature_names: List[str],\n",
    "    max_display: int = 20\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Analyze feature importance using SHAP values with proper handling for different model types.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained ML model\n",
    "        X_train: Training features DataFrame\n",
    "        feature_names: List of feature names\n",
    "        max_display: Maximum number of features to display\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # For tree-based models (Random Forest, XGBoost)\n",
    "        if isinstance(model, (RandomForestClassifier, XGBClassifier)):\n",
    "            # Use TreeExplainer for tree-based models\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            \n",
    "            # Calculate sample size\n",
    "            full_size = len(X_train)\n",
    "            sample_size = 1000 if full_size > 1000 else full_size\n",
    "            \n",
    "            # Sample data and ensure it's a DataFrame\n",
    "            X_sample = X_train.sample(n=sample_size, random_state=42)\n",
    "            \n",
    "            # Calculate SHAP values\n",
    "            shap_values = explainer.shap_values(X_sample)\n",
    "            \n",
    "            # Handle different SHAP value formats\n",
    "            if isinstance(shap_values, list):\n",
    "                shap_values = shap_values[1]  # Get values for class 1\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            # Use absolute mean for sorting features\n",
    "            feature_importance = np.abs(shap_values).mean(0)\n",
    "            feature_importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': feature_importance\n",
    "            })\n",
    "            feature_importance_df = feature_importance_df.sort_values(\n",
    "                'importance', ascending=False\n",
    "            ).head(max_display)\n",
    "            \n",
    "            plt.barh(\n",
    "                range(len(feature_importance_df)),\n",
    "                feature_importance_df['importance']\n",
    "            )\n",
    "            plt.yticks(\n",
    "                range(len(feature_importance_df)),\n",
    "                feature_importance_df['feature']\n",
    "            )\n",
    "            plt.xlabel('mean(|SHAP value|)')\n",
    "            plt.title('Feature Importance (SHAP values)')\n",
    "            \n",
    "        # For linear models (Logistic Regression)\n",
    "        elif isinstance(model, LogisticRegression):\n",
    "            # For linear models, use coefficients directly\n",
    "            importance = np.abs(model.coef_[0])\n",
    "            feature_importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            })\n",
    "            feature_importance_df = feature_importance_df.sort_values(\n",
    "                'importance', ascending=False\n",
    "            ).head(max_display)\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(\n",
    "                range(len(feature_importance_df)),\n",
    "                feature_importance_df['importance']\n",
    "            )\n",
    "            plt.yticks(\n",
    "                range(len(feature_importance_df)),\n",
    "                feature_importance_df['feature']\n",
    "            )\n",
    "            plt.xlabel('|Coefficient|')\n",
    "            plt.title('Feature Importance (Logistic Regression Coefficients)')\n",
    "            \n",
    "        # For neural networks (MLPClassifier)\n",
    "        elif isinstance(model, MLPClassifier):\n",
    "            # Use permutation importance for neural networks\n",
    "            from sklearn.inspection import permutation_importance\n",
    "            \n",
    "            result = permutation_importance(\n",
    "                model, X_train, y_train,\n",
    "                n_repeats=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            feature_importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': result.importances_mean\n",
    "            })\n",
    "            feature_importance_df = feature_importance_df.sort_values(\n",
    "                'importance', ascending=False\n",
    "            ).head(max_display)\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(\n",
    "                range(len(feature_importance_df)),\n",
    "                feature_importance_df['importance']\n",
    "            )\n",
    "            plt.yticks(\n",
    "                range(len(feature_importance_df)),\n",
    "                feature_importance_df['feature']\n",
    "            )\n",
    "            plt.xlabel('Permutation Importance')\n",
    "            plt.title('Feature Importance (Permutation)')\n",
    "        \n",
    "        else:\n",
    "            print(f\"Feature importance analysis not implemented for model type: {type(model)}\")\n",
    "            return\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print numerical values\n",
    "        print(\"\\nFeature Importance Values:\")\n",
    "        print(feature_importance_df.to_string(index=False))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature importance analysis: {str(e)}\")\n",
    "        \n",
    "        # Fallback to basic feature importance for tree-based models\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': model.feature_importances_\n",
    "            })\n",
    "            importances = importances.sort_values(\n",
    "                'importance', ascending=False\n",
    "            ).head(max_display)\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(range(len(importances)), importances['importance'])\n",
    "            plt.yticks(\n",
    "                range(len(importances)),\n",
    "                importances['feature']\n",
    "            )\n",
    "            plt.xlabel('Feature Importance')\n",
    "            plt.title(\"Feature Importance (Model's Built-in Method)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"\\nFeature Importance Values (Fallback Method):\")\n",
    "            print(importances.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dc0ee26-9983-4476-9af9-a25b48fa48bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_ml_pipeline(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    feature_cols: List[str],\n",
    "    train_end_month: str = train_end_month,\n",
    "    scale: bool = False,\n",
    "    use_feature_selection: bool = False,\n",
    "    feature_selection_method: str = None,\n",
    "    use_shap: bool = False \n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Run the complete ML pipeline with optional feature selection and SHAP analysis.\n",
    "    \n",
    "    Args:\n",
    "        df: Input Pandas DataFrame\n",
    "        target_col: Name of target column\n",
    "        feature_cols: List of feature column names\n",
    "        use_feature_selection: Whether to use feature selection (default: False)\n",
    "        feature_selection_method: Method for feature selection ('rf' or 'rfe')\n",
    "        use_shap: Whether to use SHAP for feature importance analysis (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of model performances\n",
    "    \"\"\"\n",
    "    # Ensure input is a pandas DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test = prepare_data(df, target_col, feature_cols, train_end_month, scale=True)\n",
    "    \n",
    "    # Feature selection (if enabled)\n",
    "    if use_feature_selection:\n",
    "        print(\"\\nPerforming feature selection...\")\n",
    "        X_train_final, selected_features = select_features(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            feature_cols,\n",
    "            method=feature_selection_method\n",
    "        )\n",
    "        X_test_final = X_test[selected_features]\n",
    "        print(f\"Selected {len(selected_features)} features\")\n",
    "        print(\"Selected features:\", selected_features)\n",
    "    else:\n",
    "        X_train_final = X_train\n",
    "        X_test_final = X_test\n",
    "        selected_features = feature_cols\n",
    "        print(\"All features used\")\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv = create_time_series_cv(X_train_final)\n",
    "    \n",
    "    # Calculate class weight properly for pandas Series\n",
    "    n_samples = len(y_train)\n",
    "    n_positives = y_train.sum()\n",
    "    class_weight = n_samples / (2 * n_positives)  # adjusted class weight calculation\n",
    "    \n",
    "    # Initialize models with class weights\n",
    "    models = {\n",
    "        'logistic': LogisticRegression(\n",
    "            class_weight='balanced', \n",
    "            random_state=42,\n",
    "            max_iter=1000\n",
    "        ),\n",
    "        'random_forest': RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            class_weight='balanced', \n",
    "            random_state=42\n",
    "        ),\n",
    "        'xgboost': XGBClassifier(\n",
    "            scale_pos_weight=class_weight, \n",
    "            random_state=42\n",
    "        ),\n",
    "        'neural_network': MLPClassifier(\n",
    "            hidden_layer_sizes=(100, 50), \n",
    "            max_iter=1000, \n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        results[name] = train_evaluate_model(\n",
    "            model, \n",
    "            X_train_final, \n",
    "            X_test_final, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            cv\n",
    "        )\n",
    "        \n",
    "        print(f\"Plotting learning curves for {name}...\")\n",
    "        plot_learning_curves(model, X_train_final, y_train, cv)\n",
    "        \n",
    "        if use_shap:\n",
    "            print(f\"Analyzing feature importance for {name} using SHAP...\")\n",
    "            analyze_feature_importance(model, X_train_final, selected_features)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"\\nMetrics for {name}:\")\n",
    "        for metric_name, value in results[name].items():\n",
    "            print(f\"{metric_name}: {value:.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "213dfd6e-3375-43a3-8588-33b9bf51b6dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "results = run_ml_pipeline(\n",
    "    df=hcp_feats_master_w_target_pdf,\n",
    "    target_col=target_col_nm,\n",
    "    feature_cols=feat_cols_nm_lst,\n",
    "    scale=True,\n",
    "    use_feature_selection = False,\n",
    "    feature_selection_method = 'rf',\n",
    "    use_shap = True \n",
    ")\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nResults for {model_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a807d2-838e-4d90-96b7-6482d8760374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f360ab-540d-407e-b7ac-3c0a1bfb68c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "(Clone) 01_training_model_jivi_writers_v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
