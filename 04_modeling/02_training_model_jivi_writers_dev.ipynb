{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb7944c-e4c3-4839-93fd-8f1022a025e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training binary classification model for Jivi restart writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb8e736-30ce-4eaf-b8e9-eeee60a68ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04e44c0d-119f-4310-ae0a-729946c0a1cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563d5487-0e02-48ad-b4d8-4430c5d76991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import builtins\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, \n",
    "    f1_score, precision_recall_curve, auc, confusion_matrix, classification_report\n",
    ")\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d632a080-68e8-46ad-acd8-9e25f7b7a4bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**User-defined functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e35517e-9948-4d7f-93ba-e32869ece1cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_prediction_probability_distribution(y_pred_proba, y_true, figsize=(12, 6), threshold=0.5):\n",
    "    \"\"\"\n",
    "    Plot the distribution of prediction probabilities for both classes\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred_proba: Predicted probabilities from the model\n",
    "    y_true: True labels\n",
    "    figsize: Size of the figure (width, height)\n",
    "    threshold: Decision threshold for classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure and axis\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Get probabilities for class 1\n",
    "    probabilities = y_pred_proba\n",
    "    \n",
    "    # Separate probabilities for actual positive and negative classes\n",
    "    prob_positive = probabilities[y_true == 1]\n",
    "    prob_negative = probabilities[y_true == 0]\n",
    "    \n",
    "    # Create the distribution plot\n",
    "    sns.kdeplot(prob_negative, label='Class 0 (Actual)', color='blue', shade=True)\n",
    "    sns.kdeplot(prob_positive, label='Class 1 (Actual)', color='red', shade=True)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Distribution of Predicted Probabilities by Actual Class', fontsize=12)\n",
    "    plt.xlabel('Predicted Probability of Class 1', fontsize=10)\n",
    "    plt.ylabel('Density', fontsize=10)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical line at the specified threshold\n",
    "    plt.axvline(x=threshold, color='green', linestyle='--', alpha=0.5, label=f'Decision Threshold ({threshold})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nProbability Distribution Statistics:\")\n",
    "    print(f\"Class 0 - Mean: {np.mean(prob_negative):.3f}, Std: {np.std(prob_negative):.3f}\")\n",
    "    print(f\"Class 1 - Mean: {np.mean(prob_positive):.3f}, Std: {np.std(prob_positive):.3f}\")\n",
    "\n",
    "# Assuming you have your model predictions stored in y_pred_proba and actual values in the dataframe\n",
    "# Replace 'your_model' with your actual model\n",
    "# y_pred_proba = your_model.predict_proba(X_test)  # If you're working with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba09eaa1-c4a5-4bd8-a7b0-c83d136535cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_prediction_probability_histogram(y_pred_proba, y_true, bins=50, figsize=(12, 6), threshold=0.5):\n",
    "    \"\"\"\n",
    "    Plot histogram of prediction probabilities for both classes\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred_proba: Predicted probabilities from the model\n",
    "    y_true: True labels\n",
    "    bins: Number of bins for histogram\n",
    "    figsize: Size of the figure (width, height)\n",
    "    threshold: Decision threshold for classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure and axis\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Get probabilities for class 1\n",
    "    probabilities = y_pred_proba\n",
    "    \n",
    "    # Separate probabilities for actual positive and negative classes\n",
    "    prob_positive = probabilities[y_true == 1]\n",
    "    prob_negative = probabilities[y_true == 0]\n",
    "    \n",
    "    # Create histograms\n",
    "    plt.hist(prob_negative, bins=bins, alpha=0.6, color='blue', \n",
    "             label=f'Class 0 (n={len(prob_negative)})', \n",
    "             density=True)\n",
    "    plt.hist(prob_positive, bins=bins, alpha=0.6, color='red', \n",
    "             label=f'Class 1 (n={len(prob_positive)})', \n",
    "             density=True)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Distribution of Predicted Probabilities by Actual Class', fontsize=12)\n",
    "    plt.xlabel('Predicted Probability of Class 1', fontsize=10)\n",
    "    plt.ylabel('Density', fontsize=10)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical line at the specified threshold\n",
    "    plt.axvline(x=threshold, color='green', linestyle='--', alpha=0.5, \n",
    "                label=f'Decision Threshold ({threshold})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nProbability Distribution Statistics:\")\n",
    "    print(f\"Class 0 - Mean: {np.mean(prob_negative):.3f}, Std: {np.std(prob_negative):.3f}\")\n",
    "    print(f\"Class 1 - Mean: {np.mean(prob_positive):.3f}, Std: {np.std(prob_positive):.3f}\")\n",
    "    print(f\"\\nClass 0 count: {len(prob_negative)}\")\n",
    "    print(f\"Class 1 count: {len(prob_positive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e955d4f6-6bf7-4cb1-a7eb-3f5585d57a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def optimize_threshold_best_precision(y_true, y_prob):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "    best_threshold = 0.5\n",
    "    best_precision = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        \n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78855a80-7b0d-422b-abda-448d19c870ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def optimize_threshold_best_recall(y_true, y_prob):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "    best_threshold = 0.5\n",
    "    best_recall = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        \n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed6cb84a-5a2d-4ab0-9c30-c36dd6ae281c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_pred_proba, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate and print various classification metrics.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): True labels.\n",
    "    y_pred (array-like): Predicted labels.\n",
    "    y_pred_proba (array-like): Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing various classification metrics.\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'auc_roc': roc_auc_score(y_true, y_pred_proba),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "    # Calculate PR AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    metrics['auc_pr'] = auc(recall, precision)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics['TNs'] = cm[0, 0]\n",
    "    metrics['FPs'] = cm[0, 1]\n",
    "    metrics['FNs'] = cm[1, 0]\n",
    "    metrics['TPs'] = cm[1, 1]\n",
    "\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.3f}\")\n",
    "\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix with Counts')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot confusion matrix with percentages\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.2%', cmap='Blues', cbar=False, \n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix with Percentages')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot y_pred_proba histogram with respect to classes in y\n",
    "    if y_pred_proba is not None:\n",
    "        if threshold != 0.5:\n",
    "            # Create the plot with given threshold val\n",
    "            plot_prediction_probability_histogram(y_pred_proba=y_pred_proba, \n",
    "                                                  y_true=y_true, \n",
    "                                                  threshold=threshold)\n",
    "        else:\n",
    "            # Create the plot with default threshold val\n",
    "            plot_prediction_probability_histogram(y_pred_proba=y_pred_proba,\n",
    "                                                  y_true=y_true)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c5201ff-a0fb-4459-8fdb-c872f58d8778",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_top_shap_reasons(shap_values, feature_names, hcp_feats_master_w_target_pdf):\n",
    "    \"\"\"\n",
    "    Get top 3 SHAP reasons for each BH_ID and add them to the original DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    shap_values: SHAP values from explainer\n",
    "    feature_names: List of feature names used in the model\n",
    "    hcp_feats_master_w_target_pdf: Original DataFrame containing BH_ID and features\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with added columns for top 3 SHAP reasons and their values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert SHAP values to numpy array if they aren't already\n",
    "    if not isinstance(shap_values, np.ndarray):\n",
    "        shap_values = shap_values.values\n",
    "    \n",
    "    # Create DataFrame with SHAP values\n",
    "    shap_df = pd.DataFrame(shap_values, columns=feature_names)\n",
    "    \n",
    "    # Initialize lists to store results\n",
    "    first_reasons = []\n",
    "    first_values = []\n",
    "    second_reasons = []\n",
    "    second_values = []\n",
    "    third_reasons = []\n",
    "    third_values = []\n",
    "    \n",
    "    # For each row, get top 3 features by absolute SHAP value\n",
    "    for idx in range(len(shap_df)):\n",
    "        # Convert row to numeric values and get absolute values\n",
    "        row_values = shap_df.iloc[idx].astype(float)\n",
    "        abs_values = np.abs(row_values)\n",
    "        \n",
    "        # Get top 3 indices\n",
    "        top3_idx = abs_values.argsort()[-3:][::-1]\n",
    "        \n",
    "        # Get feature names and values for top 3\n",
    "        top3_features = [feature_names[i] for i in top3_idx]\n",
    "        top3_values = [row_values[i] for i in top3_idx]\n",
    "        \n",
    "        # Append to lists\n",
    "        first_reasons.append(top3_features[0])\n",
    "        first_values.append(top3_values[0])\n",
    "        second_reasons.append(top3_features[1])\n",
    "        second_values.append(top3_values[1])\n",
    "        third_reasons.append(top3_features[2])\n",
    "        third_values.append(top3_values[2])\n",
    "    \n",
    "    # Create result DataFrame\n",
    "    result_df = hcp_feats_master_w_target_pdf.copy()\n",
    "    \n",
    "    # Add new columns\n",
    "    result_df['first_reason'] = first_reasons\n",
    "    result_df['fst_reason_shap_val'] = first_values\n",
    "    result_df['second_reason'] = second_reasons\n",
    "    result_df['scd_reason_shap_val'] = second_values\n",
    "    result_df['third_reason'] = third_reasons\n",
    "    result_df['thd_reason_shap_val'] = third_values\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a593df-bed7-48b9-b704-a255b653aae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Start of modeling workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cf81b8-0210-4341-8583-eb34f215a918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00_config/set-up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "287c301a-8239-4b62-a664-76bcbe38cfda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Month and Date parameters for manual control\n",
    "first_month = \"2019-12\"\n",
    "last_month = \"2024-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0bbca16-6d71-49c9-a460-e10cd2767ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading the feature master table from Hivestore\n",
    "hcp_feats_master_w_target_sdf = spark.sql(\"SELECT * FROM jivi_new_writer_model.hcp_feats_master_w_target\")\n",
    "print(\n",
    "    \"Row count: \",\n",
    "    hcp_feats_master_w_target_sdf.count(),\n",
    "    \"Column Count: \",\n",
    "    len(hcp_feats_master_w_target_sdf.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbded0fe-6ffb-4101-b743-596ade038d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Converting Spark dataframe to Pandas dataframe\n",
    "hcp_feats_master_w_target_pdf = hcp_feats_master_w_target_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ca94fc-1c5f-400c-83a8-9a9f4aaee2ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feat_cols = [col for col in hcp_feats_master_w_target_pdf.columns if col not in ['BH_ID', 'COHORT_MONTH', 'JIVI_NEW_WRITER_FLG']]\n",
    "binary_cols = ['AFFL_WI_INSN', 'AFFL_WI_JIVI_HCP_12M']\n",
    "numeric_cols = [col for col in feat_cols if col not in binary_cols]\n",
    "target_col_nm = 'JIVI_NEW_WRITER_FLG'\n",
    "print(\"Names of binary feats\", binary_cols)\n",
    "print(\"Names of numeric feats\", numeric_cols)\n",
    "print(\"Number of features: \", len(feat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e147b3f-bcc1-4dcb-aa84-6d9dfe2c415f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = hcp_feats_master_w_target_pdf[feat_cols]\n",
    "y = hcp_feats_master_w_target_pdf[target_col_nm]\n",
    "print(\"Positives/Negatives in the dataset: \\n\", y.value_counts())\n",
    "print(\"Shape of dataset before oversampling: \", hcp_feats_master_w_target_pdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ccd4148-d4de-4a88-89b0-e2429329916a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Applying scaling to the continuous features in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d212ced4-fbb1-4f80-bff2-9db19c69dafc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = pd.DataFrame(\n",
    "  scaler.fit_transform(X[numeric_cols]),\n",
    "  columns=numeric_cols,\n",
    "  index=X.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50bf6400-a8c2-496f-914b-87ef25628a8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Save the StandardScaler object for later use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc42151f-c284-4896-a265-a16585acc85d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the directory if it does not exist\n",
    "if not dbutils.fs.ls('/FileStore/jivi_new_writer_model/prod/'):\n",
    "    dbutils.fs.mkdirs('/FileStore/jivi_new_writer_model/prod/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbd2a829-83cb-40b5-8f03-27190a900063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the scaler object to the Databricks Filesystem (DBFS)\n",
    "joblib.dump(scaler, '/dbfs/FileStore/jivi_new_writer_model/prod/standard_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662b557e-5f56-4c1a-a4d5-49de45fc1cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Applying Oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf9c587e-93a4-445e-b7fa-50da2fc85571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# applying oversampling for the minority class\n",
    "ros = RandomOverSampler()\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X, y)\n",
    "hcp_feats_master_w_target_oversampled_pdf = pd.concat([X_oversampled, y_oversampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cb21811-f8f4-4016-9a54-f2defac34526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Positives/Negatives in dataset after oversampling: \\n\", hcp_feats_master_w_target_oversampled_pdf.JIVI_NEW_WRITER_FLG.value_counts())\n",
    "print(\"Shape of dataset after oversampling: \", hcp_feats_master_w_target_oversampled_pdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dad9de4e-a653-4b7b-bd90-42d590276127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Applying undersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a807d2-838e-4d90-96b7-6482d8760374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# applying undersampling for the majority class\n",
    "rus = RandomUnderSampler()\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X, y)\n",
    "hcp_feats_master_w_target_undersampled_pdf = pd.concat([X_undersampled, y_undersampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f360ab-540d-407e-b7ac-3c0a1bfb68c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Positives/Negatives in dataset after undersampling: \\n\", hcp_feats_master_w_target_undersampled_pdf.JIVI_NEW_WRITER_FLG.value_counts())\n",
    "print(\"Shape of dataset after undersampling: \", hcp_feats_master_w_target_undersampled_pdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5235b65-d628-4443-8c3b-3d4da438175e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Overall logistic regression performs consistently and undersampling seems to be working better than oversampling for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd98795-82a6-4ebf-a4f0-cf458c95be2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For Ridge regression\n",
    "# logit_reg = LogisticRegression(penalty='l2', class_weight='balanced', random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cbf5688-d6fa-4ec9-b7f0-9f3e25e4f97a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Lasso logistic regression models\n",
    "logit_reg_undersampled = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000)\n",
    "logit_reg_oversampled = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc3e984-4635-4d2d-9970-f9d7cd8d397c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Fit the models on the respective datasets\n",
    "# mlflow.autolog(disable=True)\n",
    "# logit_reg_undersampled.fit(X_undersampled, y_undersampled)\n",
    "# logit_reg_oversampled.fit(X_oversampled, y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfa49ff1-34b2-4d00-a1de-e87a55664a74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the undersampled model\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Lasso - Undersampled\") as run:\n",
    "    mlflow.autolog()\n",
    "    logit_reg_undersampled.fit(X_undersampled, y_undersampled)\n",
    "    mlflow.sklearn.log_model(logit_reg_undersampled, \"logit_reg_undersampled\")\n",
    "    model_uri = f\"runs:/{run.info.run_id}/logit_reg_undersampled\"\n",
    "    mlflow.register_model(model_uri, \"LogisticRegressionLassoUndersampled\")\n",
    "\n",
    "# Log the oversampled model\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Lasso - Oversampled\") as run:\n",
    "    mlflow.autolog()\n",
    "    logit_reg_oversampled.fit(X_oversampled, y_oversampled)\n",
    "    mlflow.sklearn.log_model(logit_reg_oversampled, \"logit_reg_oversampled\")\n",
    "    model_uri = f\"runs:/{run.info.run_id}/logit_reg_oversampled\"\n",
    "    mlflow.register_model(model_uri, \"LogisticRegressionLassoOversampled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd68156-b4d3-464d-91b4-503cb0ff57ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**List model versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c023211b-f22d-4f53-9ed5-9a5a7e16eaaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "for mv in client.search_model_versions(\"name='LogisticRegressionLassoOversampled'\"):\n",
    "    print(f\"version: {mv.version}, stage: {mv.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a2f331b-3eed-4f54-8de8-1c5eff9388fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "for mv in client.search_model_versions(\"name='LogisticRegressionLassoUndersampled'\"):\n",
    "    print(f\"version: {mv.version}, stage: {mv.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8597b6eb-fbac-4853-a5b6-70efc4335a2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Transition the latest version of models to production**\n",
    "\n",
    "Note: Valid stages are 'Production', 'Staging', 'Archived', 'None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d28fee-5d4b-462d-83a8-92a1f2502f34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the latest version of the model\n",
    "latest_version = builtins.max([int(mv.version) for mv in client.search_model_versions(\"name='LogisticRegressionLassoOversampled'\")])\n",
    "print(\"Latest model version for LogisticRegressionLassoOversampled: \", latest_version)\n",
    "# Transition the latest version to production\n",
    "client.transition_model_version_stage(\n",
    "    name=\"LogisticRegressionLassoOversampled\",\n",
    "    version=latest_version,\n",
    "    # stage=\"Production\",\n",
    "    stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d2be4a8-a412-4029-b3c9-a6683a0e4987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the latest version of the model\n",
    "latest_version = builtins.max([int(mv.version) for mv in client.search_model_versions(\"name='LogisticRegressionLassoUndersampled'\")])\n",
    "print(\"Latest model version for LogisticRegressionLassoUndersampled: \", latest_version)\n",
    "# Transition the latest version to production\n",
    "client.transition_model_version_stage(\n",
    "    name=\"LogisticRegressionLassoUndersampled\",\n",
    "    version=latest_version,\n",
    "    stage=\"Production\",\n",
    "    # stage=\"Staging\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29848b8c-ea88-47a1-b57e-99d69232b61c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee0965e5-fbf3-493b-8f59-d773fc312408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check the performance of the model, fitted to Oversampled class balanced dataset, against the whole dataset to assess what can be the upper bounds on the model performance on the unseen/new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e44cf3d3-2814-4b51-8aff-1483d4e2ee41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the full dataset\n",
    "y_pred = logit_reg_oversampled.predict(X)\n",
    "y_pred_proba = logit_reg_oversampled.predict_proba(X)[:, 1]\n",
    "\n",
    "calculate_metrics(y, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed914c00-ae78-43dc-a81c-ef27fa50d27f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check the performance of the model, fitted to Undersampled class balanced dataset, against the whole dataset to assess what can be the upper bounds on the model performance on the unseen/new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b43017d6-c19f-4cbc-bfa7-bc5cc564885b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the full dataset\n",
    "y_pred = logit_reg_undersampled.predict(X)\n",
    "y_pred_proba = logit_reg_undersampled.predict_proba(X)[:, 1]\n",
    "\n",
    "calculate_metrics(y, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cacb0be-a551-4227-93e9-d29eda2a434a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ADDING THE PREDICTED PROBABILITIES TO THE MASTER DATAFRAME\n",
    "hcp_feats_master_w_target_pdf['y_pred_proba'] = y_pred_proba\n",
    "hcp_feats_master_w_target_pdf['y_pred'] = y_pred\n",
    "display(hcp_feats_master_w_target_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39ad3a55-0c14-440b-b1cf-b29f05ac0e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Go ahead with logistic regression fitted to Undersampled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99561e81-4761-457e-9c04-b84afe83cff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Optimize probability cut-offs for Precision and Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7188136-41b5-4c8f-a005-418778160a82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal threshold for PRECISION\n",
    "threshold = float(optimize_threshold_best_precision(y, y_pred_proba))\n",
    "print(\"Optimal probability threshold for precision: \", threshold)  \n",
    "# Make final predictions\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "# Calculate metrics\n",
    "calculate_metrics(y, y_pred, y_pred_proba, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33a0a1e3-e5c2-4019-b1f5-24698d22766e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal threshold for RECALL\n",
    "threshold = optimize_threshold_best_recall(y, y_pred_proba) \n",
    "print(\"Optimal probability threshold for recall: \", threshold)  \n",
    "# Make final predictions\n",
    "# y_pred = (y_pred_proba >= 0.3).astype(int)\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "# Calculate metrics\n",
    "calculate_metrics(y, y_pred, y_pred_proba, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc6ccaa0-b50f-4525-9f2e-6d8639a9e278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.23\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "# Calculate metrics\n",
    "calculate_metrics(y, y_pred, y_pred_proba, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3845dd75-65bd-4325-b2d7-bc811aaf4b51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.72\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "# Calculate metrics\n",
    "calculate_metrics(y, y_pred, y_pred_proba, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ac72571-f23b-41e0-8aef-11376dfd5d3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b98766b-f3cc-4530-9be8-a2e2764af01b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2c84327-c461-41f7-ada6-2a2e4f8c430a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# GET MODEL COEFFICIENTS\n",
    "co_eff = logit_reg_undersampled.coef_[0]\n",
    "\n",
    "# Put in DataFrame and sort by effect size\n",
    "co_eff_df = pd.DataFrame()\n",
    "co_eff_df['feature'] = feat_cols\n",
    "co_eff_df['co_eff'] = co_eff\n",
    "co_eff_df['abs_co_eff'] = np.abs(co_eff)\n",
    "co_eff_df_sorted = co_eff_df.sort_values(by='abs_co_eff', ascending=False, inplace=False)\n",
    "display(co_eff_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83079f71-24a1-473f-ab6e-801f333c12f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SHAP feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2299d64b-b065-4763-a76a-26dc1c7ee2f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(logit_reg_undersampled, X_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65067614-3e2f-4bcb-aa16-c8a8f3576d10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "shap_values_undersampled = explainer(X_undersampled)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6304ea95-df4f-4146-8f10-4f71aa575a62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values = explainer(X_undersampled), \n",
    "                  features = X_undersampled.values,\n",
    "                  feature_names = X_undersampled.columns.values,\n",
    "                  plot_type='dot',\n",
    "                  max_display=15,\n",
    "                  show=False)\n",
    "plt.tight_layout(rect=[0, 0, 2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2af05ec3-ef21-429d-aebb-f391d1aba891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values = explainer(X_undersampled), \n",
    "                  features = X_undersampled.values,\n",
    "                  feature_names = X_undersampled.columns.values,\n",
    "                  plot_type='dot',\n",
    "                  max_display=30,\n",
    "                  show=False)\n",
    "plt.tight_layout(rect=[0, 0, 2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35bc29c8-075b-419c-87ab-9e5d9443b307",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values = explainer(X_undersampled), \n",
    "                  features = X_undersampled.values,\n",
    "                  feature_names = X_undersampled.columns.values,\n",
    "                  plot_type='bar',\n",
    "                  max_display=50,\n",
    "                  show=False)\n",
    "plt.tight_layout(rect=[0, 0, 2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bddb2bab-561c-4d1a-917c-68e8359879bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values = explainer(X), \n",
    "                  features = X.values,\n",
    "                  feature_names = X.columns.values,\n",
    "                  plot_type='dot',\n",
    "                  max_display=15,\n",
    "                  show=False)\n",
    "plt.tight_layout(rect=[0, 0, 2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5b3a755-6dec-4b20-9614-d1c487e1cdee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values = explainer(X), \n",
    "                  features = X.values,\n",
    "                  feature_names = X.columns.values,\n",
    "                  plot_type='bar',\n",
    "                  max_display=15,\n",
    "                  show=False)\n",
    "plt.tight_layout(rect=[0, 0, 2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c47b4065-3bd9-46e9-a35f-ab26dbdbf8d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2408426e-a411-49f9-9338-7d6efa57f020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Initialize SHAP JavaScript visualization\n",
    "# shap.initjs()\n",
    "\n",
    "# # Select an index for the SHAP force plot\n",
    "# ind = 1\n",
    "\n",
    "# # Plot the SHAP force plot\n",
    "# shap.force_plot(shap_values[ind], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61d5ff03-f04f-4c72-800f-d77390bdb448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# top 20 features to show importance\n",
    "max_display = 50\n",
    "\n",
    "# For linear models, use coefficients directly\n",
    "importance = np.abs(logit_reg_undersampled.coef_[0])\n",
    "# importance = logit_reg_undersampled.coef_[0]\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feat_cols,\n",
    "    'importance': importance\n",
    "})\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    'importance', ascending=False\n",
    ").head(max_display)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(\n",
    "    range(len(feature_importance_df)),\n",
    "    feature_importance_df['importance']\n",
    ")\n",
    "plt.yticks(\n",
    "    range(len(feature_importance_df)),\n",
    "    feature_importance_df['feature']\n",
    ")\n",
    "plt.xlabel('|Coefficient|')\n",
    "plt.title('Feature Importance (Logistic Regression Coefficients)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e30a10-3af2-4545-8c1f-fa31b82453cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23af3728-af8e-4ec2-8d3e-12e82e4687af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef00b62-60ff-4eb4-94ce-629f5fd57e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extracting reasons based on SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb881c44-a185-48ac-a3be-d183d39f08f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert SHAP values to a DataFrame\n",
    "shap_values_df = pd.DataFrame(shap_values.values, columns=feat_cols)\n",
    "\n",
    "# Get the feature with the highest absolute SHAP value for each instance\n",
    "top_reasons = shap_values_df.abs().idxmax(axis=1)\n",
    "\n",
    "# Create a DataFrame to store the top reason and its SHAP value\n",
    "top_reasons_df = pd.DataFrame({\n",
    "    'instance': np.arange(len(top_reasons)),\n",
    "    'top_reason': top_reasons,\n",
    "    'shap_value': shap_values_df.lookup(np.arange(len(top_reasons)), top_reasons)\n",
    "})\n",
    "\n",
    "display(top_reasons_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "362b2527-3b51-412a-b328-9f6ea0520cf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Get top 3 reasons and values from SHAP for each HCP in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4cf0359-5271-42c6-ada8-9b3d29cc30df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be1e5773-c013-4267-957d-ac3d37ee055d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming you have your feature names in a list called 'feature_names'\n",
    "# feature_names should be the list of column names used in model training\n",
    "\n",
    "hcp_feats_w_shap_reasons_df = get_top_shap_reasons(shap_values, \n",
    "                               feat_cols, \n",
    "                               hcp_feats_master_w_target_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e1797cb-9d0b-43bf-9e84-7d8299fe5899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(hcp_feats_w_shap_reasons_df.sort_values(\n",
    "    by=[\"JIVI_NEW_WRITER_FLG\", \"BH_ID\", \"COHORT_MONTH\"], \n",
    "    ascending=[False, True, True]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acffe67b-f7df-45dd-a5d8-635116ad8ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display first few rows to verify\n",
    "display(hcp_feats_w_shap_reasons_df[['BH_ID', 'first_reason', 'fst_reason_shap_val', \n",
    "                 'second_reason', 'scd_reason_shap_val',\n",
    "                 'third_reason', 'thd_reason_shap_val']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0639eb37-e182-4d7f-a63e-34ae26929af8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8993054277976380,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02_training_model_jivi_writers_dev",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
