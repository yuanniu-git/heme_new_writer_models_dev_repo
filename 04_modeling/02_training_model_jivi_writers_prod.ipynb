{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb7944c-e4c3-4839-93fd-8f1022a025e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training binary classification model for Jivi restart writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb8e736-30ce-4eaf-b8e9-eeee60a68ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04e44c0d-119f-4310-ae0a-729946c0a1cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563d5487-0e02-48ad-b4d8-4430c5d76991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mlflow\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, \n",
    "    f1_score, precision_recall_curve, auc, confusion_matrix, classification_report\n",
    ")\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cf81b8-0210-4341-8583-eb34f215a918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00_config/set-up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "287c301a-8239-4b62-a664-76bcbe38cfda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Month and Date parameters for manual control\n",
    "first_month = \"2019-12\"\n",
    "last_month = \"2024-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0bbca16-6d71-49c9-a460-e10cd2767ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading the feature master table from Hivestore\n",
    "hcp_feats_master_w_target_sdf = spark.sql(\"SELECT * FROM jivi_new_writer_model.hcp_feats_master_w_target\")\n",
    "print(\n",
    "    \"Row count: \",\n",
    "    hcp_feats_master_w_target_sdf.count(),\n",
    "    \"Column Count: \",\n",
    "    len(hcp_feats_master_w_target_sdf.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbded0fe-6ffb-4101-b743-596ade038d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Converting Spark dataframe to Pandas dataframe\n",
    "hcp_feats_master_w_target_pdf = hcp_feats_master_w_target_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ca94fc-1c5f-400c-83a8-9a9f4aaee2ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feat_cols = [col for col in hcp_feats_master_w_target_pdf.columns if col not in ['BH_ID', 'COHORT_MONTH', 'JIVI_NEW_WRITER_FLG']]\n",
    "binary_cols = ['AFFL_WI_INSN', 'AFFL_WI_JIVI_HCP_12M']\n",
    "numeric_cols = [col for col in feat_cols if col not in binary_cols]\n",
    "target_col_nm = 'JIVI_NEW_WRITER_FLG'\n",
    "print(\"Names of binary feats\", binary_cols)\n",
    "print(\"Names of numeric feats\", numeric_cols)\n",
    "print(\"Number of features: \", len(feat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e147b3f-bcc1-4dcb-aa84-6d9dfe2c415f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = hcp_feats_master_w_target_pdf[feat_cols]\n",
    "y = hcp_feats_master_w_target_pdf[target_col_nm]\n",
    "print(\"Positives/Negatives in the dataset: \\n\", y.value_counts())\n",
    "print(\"Shape of dataset before oversampling: \", hcp_feats_master_w_target_pdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662b557e-5f56-4c1a-a4d5-49de45fc1cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Applying Oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf9c587e-93a4-445e-b7fa-50da2fc85571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# applying oversampling for the minority class\n",
    "ros = RandomOverSampler()\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X, y)\n",
    "hcp_feats_master_w_target_oversampled_pdf = pd.concat([X_oversampled, y_oversampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cb21811-f8f4-4016-9a54-f2defac34526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Positives/Negatives in dataset after oversampling: \\n\", hcp_feats_master_w_target_oversampled_pdf.JIVI_NEW_WRITER_FLG.value_counts())\n",
    "print(\"Shape of dataset after oversampling: \", hcp_feats_master_w_target_oversampled_pdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dad9de4e-a653-4b7b-bd90-42d590276127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Applying undersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a807d2-838e-4d90-96b7-6482d8760374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# applying undersampling for the majority class\n",
    "rus = RandomUnderSampler()\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X, y)\n",
    "hcp_feats_master_w_target_undersampled_pdf = pd.concat([X_undersampled, y_undersampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f360ab-540d-407e-b7ac-3c0a1bfb68c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Positives/Negatives in dataset after undersampling: \\n\", hcp_feats_master_w_target_undersampled_pdf.JIVI_NEW_WRITER_FLG.value_counts())\n",
    "print(\"Shape of dataset after undersampling: \", hcp_feats_master_w_target_undersampled_pdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5235b65-d628-4443-8c3b-3d4da438175e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Overall logistic regression performs consistently and undersampling seems to be working better than oversampling for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfd98795-82a6-4ebf-a4f0-cf458c95be2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For Ridge regression\n",
    "# logit_reg = LogisticRegression(penalty='l2', class_weight='balanced', random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cbf5688-d6fa-4ec9-b7f0-9f3e25e4f97a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Lasso logistic regression models\n",
    "logit_reg_undersampled = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000)\n",
    "logit_reg_oversampled = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc3e984-4635-4d2d-9970-f9d7cd8d397c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the models on the respective datasets\n",
    "mlflow.autolog(disable=True)\n",
    "logit_reg_undersampled.fit(X_undersampled, y_undersampled)\n",
    "logit_reg_oversampled.fit(X_oversampled, y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfa49ff1-34b2-4d00-a1de-e87a55664a74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the undersampled model\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Lasso - Undersampled\") as run:\n",
    "    logit_reg_undersampled.fit(X_undersampled, y_undersampled)\n",
    "    mlflow.sklearn.log_model(logit_reg_undersampled, \"logit_reg_undersampled\")\n",
    "    model_uri = f\"runs:/{run.info.run_id}/logit_reg_undersampled\"\n",
    "    mlflow.register_model(model_uri, \"LogisticRegressionLassoUndersampled\")\n",
    "\n",
    "# Log the oversampled model\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Lasso - Oversampled\") as run:\n",
    "    logit_reg_oversampled.fit(X_oversampled, y_oversampled)\n",
    "    mlflow.sklearn.log_model(logit_reg_oversampled, \"logit_reg_oversampled\")\n",
    "    model_uri = f\"runs:/{run.info.run_id}/logit_reg_oversampled\"\n",
    "    mlflow.register_model(model_uri, \"LogisticRegressionLassoOversampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc9f4a48-5b81-46c4-90a3-a4d7eb8464b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee0965e5-fbf3-493b-8f59-d773fc312408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check the model performance after fitting to the whole dataset to assess what can be the upper bounds on the model performance on the unseen/new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "816b5a43-2541-4518-90f1-e4c52d547234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the full dataset\n",
    "y_pred = logit_reg.predict(X)\n",
    "y_pred_proba = logit_reg.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    'auc_roc': roc_auc_score(y, y_pred_proba),\n",
    "    'precision': precision_score(y, y_pred),\n",
    "    'recall': recall_score(y, y_pred),\n",
    "    'f1': f1_score(y, y_pred),\n",
    "}\n",
    "\n",
    "# Calculate PR AUC\n",
    "precision, recall, _ = precision_recall_curve(y, y_pred_proba)\n",
    "metrics['auc_pr'] = auc(recall, precision)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "metrics['TNs'] = cm[0, 0]\n",
    "metrics['FPs'] = cm[0, 1]\n",
    "metrics['FNs'] = cm[1, 0]\n",
    "metrics['TPs'] = cm[1, 1]\n",
    "\n",
    "\n",
    "for metric_name, value in metrics.items():\n",
    "  print(f\"{metric_name}: {value:.3f}\")\n",
    "  \n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "if y_pred_proba is not None:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(y_pred_proba, bins=50)\n",
    "    plt.title('Prediction Probability Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b98766b-f3cc-4530-9be8-a2e2764af01b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hcp_feats_master_w_target_pdf['y_pred_proba'] = y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "150ac43b-20b1-42ba-9ac0-97a69d995655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(hcp_feats_master_w_target_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e35517e-9948-4d7f-93ba-e32869ece1cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_prediction_probability_distribution(y_pred_proba, y_true, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Plot the distribution of prediction probabilities for both classes\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred_proba: Predicted probabilities from the model\n",
    "    y_true: True labels\n",
    "    figsize: Size of the figure (width, height)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure and axis\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Get probabilities for class 1\n",
    "    probabilities = y_pred_proba\n",
    "    \n",
    "    # Separate probabilities for actual positive and negative classes\n",
    "    prob_positive = probabilities[y_true == 1]\n",
    "    prob_negative = probabilities[y_true == 0]\n",
    "    \n",
    "    # Create the distribution plot\n",
    "    sns.kdeplot(prob_negative, label='Class 0 (Actual)', color='blue', shade=True)\n",
    "    sns.kdeplot(prob_positive, label='Class 1 (Actual)', color='red', shade=True)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Distribution of Predicted Probabilities by Actual Class', fontsize=12)\n",
    "    plt.xlabel('Predicted Probability of Class 1', fontsize=10)\n",
    "    plt.ylabel('Density', fontsize=10)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical line at 0.5 threshold\n",
    "    plt.axvline(x=0.5, color='green', linestyle='--', alpha=0.5, label='Decision Threshold (0.5)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nProbability Distribution Statistics:\")\n",
    "    print(f\"Class 0 - Mean: {np.mean(prob_negative):.3f}, Std: {np.std(prob_negative):.3f}\")\n",
    "    print(f\"Class 1 - Mean: {np.mean(prob_positive):.3f}, Std: {np.std(prob_positive):.3f}\")\n",
    "\n",
    "# Assuming you have your model predictions stored in y_pred_proba and actual values in the dataframe\n",
    "# Replace 'your_model' with your actual model\n",
    "# y_pred_proba = your_model.predict_proba(X_test)  # If you're working with test data\n",
    "\n",
    "# Create the plot\n",
    "plot_prediction_probability_distribution(\n",
    "    y_pred_proba,  # Your predicted probabilities\n",
    "    hcp_feats_master_w_target_pdf['JIVI_NEW_WRITER_FLG']  # Your actual labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba09eaa1-c4a5-4bd8-a7b0-c83d136535cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_prediction_probability_histogram(y_pred_proba, y_true, bins=50, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Plot histogram of prediction probabilities for both classes\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred_proba: Predicted probabilities from the model\n",
    "    y_true: True labels\n",
    "    bins: Number of bins for histogram\n",
    "    figsize: Size of the figure (width, height)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure and axis\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Get probabilities for class 1\n",
    "    probabilities = y_pred_proba\n",
    "    \n",
    "    # Separate probabilities for actual positive and negative classes\n",
    "    prob_positive = probabilities[y_true == 1]\n",
    "    prob_negative = probabilities[y_true == 0]\n",
    "    \n",
    "    # Create histograms\n",
    "    plt.hist(prob_negative, bins=bins, alpha=0.6, color='blue', \n",
    "             label=f'Class 0 (n={len(prob_negative)})', \n",
    "             density=True)\n",
    "    plt.hist(prob_positive, bins=bins, alpha=0.6, color='red', \n",
    "             label=f'Class 1 (n={len(prob_positive)})', \n",
    "             density=True)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Distribution of Predicted Probabilities by Actual Class', fontsize=12)\n",
    "    plt.xlabel('Predicted Probability of Class 1', fontsize=10)\n",
    "    plt.ylabel('Density', fontsize=10)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical line at 0.5 threshold\n",
    "    plt.axvline(x=0.5, color='green', linestyle='--', alpha=0.5, \n",
    "                label='Decision Threshold (0.5)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nProbability Distribution Statistics:\")\n",
    "    print(f\"Class 0 - Mean: {np.mean(prob_negative):.3f}, Std: {np.std(prob_negative):.3f}\")\n",
    "    print(f\"Class 1 - Mean: {np.mean(prob_positive):.3f}, Std: {np.std(prob_positive):.3f}\")\n",
    "    print(f\"\\nClass 0 count: {len(prob_negative)}\")\n",
    "    print(f\"Class 1 count: {len(prob_positive)}\")\n",
    "\n",
    "# Create the plot\n",
    "plot_prediction_probability_histogram(\n",
    "    y_pred_proba,  # Your predicted probabilities\n",
    "    hcp_feats_master_w_target_pdf['JIVI_NEW_WRITER_FLG']  # Your actual labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "216b922b-9f2a-40c1-a7c8-316a435307b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99561e81-4761-457e-9c04-b84afe83cff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Optimize probability cut-offs for Precision and Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faba4c2c-f67f-41d7-a8fa-bf8799d31e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def optimize_threshold_best_precision(y_true, y_prob):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "    best_threshold = 0.5\n",
    "    best_precision = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        \n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a26b9216-3cb7-4afb-ac6a-4c04071a29b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def optimize_threshold_best_recall(y_true, y_prob):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "    best_threshold = 0.5\n",
    "    best_recall = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        \n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d5bda9-7b77-450e-86f6-8ffa4c4805b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal threshold for precision\n",
    "threshold = optimize_threshold_best_precision(y, y_pred_proba) \n",
    "print(\"Optimal probability threshold for precision: \", threshold)  \n",
    "# Make final predictions\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b645dff-2c6e-4bae-b89c-016d95dd6b04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = {\n",
    "    'auc_roc': roc_auc_score(y, y_pred_proba),\n",
    "    'precision': precision_score(y, y_pred),\n",
    "    'recall': recall_score(y, y_pred),\n",
    "    'f1': f1_score(y, y_pred),\n",
    "}\n",
    "\n",
    "# Calculate PR AUC\n",
    "precision, recall, _ = precision_recall_curve(y, y_pred_proba)\n",
    "metrics['auc_pr'] = auc(recall, precision)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "metrics['TNs'] = cm[0, 0]\n",
    "metrics['FPs'] = cm[0, 1]\n",
    "metrics['FNs'] = cm[1, 0]\n",
    "metrics['TPs'] = cm[1, 1]\n",
    "\n",
    "\n",
    "for metric_name, value in metrics.items():\n",
    "  print(f\"{metric_name}: {value:.3f}\")\n",
    "  \n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33a0a1e3-e5c2-4019-b1f5-24698d22766e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal threshold for recall\n",
    "threshold = optimize_threshold_best_recall(y, y_pred_proba) \n",
    "print(\"Optimal probability threshold for recall: \", threshold)  \n",
    "# Make final predictions\n",
    "# y_pred = (y_pred_proba >= 0.3).astype(int)\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d70a64-3ee4-4021-8963-256b59f8d22a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = {\n",
    "    'auc_roc': roc_auc_score(y, y_pred_proba),\n",
    "    'precision': precision_score(y, y_pred),\n",
    "    'recall': recall_score(y, y_pred),\n",
    "    'f1': f1_score(y, y_pred),\n",
    "}\n",
    "\n",
    "# Calculate PR AUC\n",
    "precision, recall, _ = precision_recall_curve(y, y_pred_proba)\n",
    "metrics['auc_pr'] = auc(recall, precision)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "metrics['TNs'] = cm[0, 0]\n",
    "metrics['FPs'] = cm[0, 1]\n",
    "metrics['FNs'] = cm[1, 0]\n",
    "metrics['TPs'] = cm[1, 1]\n",
    "\n",
    "\n",
    "for metric_name, value in metrics.items():\n",
    "  print(f\"{metric_name}: {value:.3f}\")\n",
    "  \n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36058385-f346-43b5-af32-cbe3b29dee03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2c84327-c461-41f7-ada6-2a2e4f8c430a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Get model co_efficients\n",
    "# co_eff = logit_reg.coef_[0]\n",
    "\n",
    "# # Put in DataFrame and sort by effect size\n",
    "# co_eff_df = pd.DataFrame()\n",
    "# co_eff_df['feature'] = feat_cols\n",
    "# co_eff_df['co_eff'] = co_eff\n",
    "# co_eff_df['abs_co_eff'] = np.abs(co_eff)\n",
    "# co_eff_df_sorted = co_eff_df.sort_values(by='abs_co_eff', ascending=False, inplace=False)\n",
    "# display(co_eff_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83079f71-24a1-473f-ab6e-801f333c12f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SHAP feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76cccc4b-c054-41e9-ac0b-37e403e25c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the SHAP explainer\n",
    "explainer = shap.Explainer(logit_reg, X_train)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_test)\n",
    "# shap_values = explainer(X_train)\n",
    "\n",
    "# Plot the SHAP summary plot\n",
    "# shap.summary_plot(shap_values, X_test, feature_names=feat_cols)\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca2a88d-5c7e-425a-9e73-af168e8cce1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values = explainer(X_train), \n",
    "                  features = X_train.values,\n",
    "                  feature_names = X_train.columns.values,\n",
    "                  plot_type='bar',\n",
    "                  max_display=15,\n",
    "                  show=False)\n",
    "plt.tight_layout(rect=[0, 0, 2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2408426e-a411-49f9-9338-7d6efa57f020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Initialize SHAP JavaScript visualization\n",
    "# shap.initjs()\n",
    "\n",
    "# # Select an index for the SHAP force plot\n",
    "# ind = 1\n",
    "\n",
    "# # Plot the SHAP force plot\n",
    "# shap.force_plot(shap_values[ind], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61d5ff03-f04f-4c72-800f-d77390bdb448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# top 20 features to show importance\n",
    "max_display = 20\n",
    "\n",
    "# For linear models, use coefficients directly\n",
    "importance = np.abs(logit_reg.coef_[0])\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feat_cols,\n",
    "    'importance': importance\n",
    "})\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    'importance', ascending=False\n",
    ").head(max_display)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(\n",
    "    range(len(feature_importance_df)),\n",
    "    feature_importance_df['importance']\n",
    ")\n",
    "plt.yticks(\n",
    "    range(len(feature_importance_df)),\n",
    "    feature_importance_df['feature']\n",
    ")\n",
    "plt.xlabel('|Coefficient|')\n",
    "plt.title('Feature Importance (Logistic Regression Coefficients)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef00b62-60ff-4eb4-94ce-629f5fd57e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extracting reasons based on SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb881c44-a185-48ac-a3be-d183d39f08f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert SHAP values to a DataFrame\n",
    "shap_values_df = pd.DataFrame(shap_values.values, columns=feat_cols)\n",
    "\n",
    "# Get the feature with the highest absolute SHAP value for each instance\n",
    "top_reasons = shap_values_df.abs().idxmax(axis=1)\n",
    "\n",
    "# Create a DataFrame to store the top reason and its SHAP value\n",
    "top_reasons_df = pd.DataFrame({\n",
    "    'instance': np.arange(len(top_reasons)),\n",
    "    'top_reason': top_reasons,\n",
    "    'shap_value': shap_values_df.lookup(np.arange(len(top_reasons)), top_reasons)\n",
    "})\n",
    "\n",
    "display(top_reasons_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_training_model_jivi_writers_prod",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
