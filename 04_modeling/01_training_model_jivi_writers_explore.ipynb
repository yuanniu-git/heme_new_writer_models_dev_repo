{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb7944c-e4c3-4839-93fd-8f1022a025e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training binary classification model for Jivi restart writers\n",
    "\n",
    "## TODO: Hyper-parameter tuning. Further champion model hunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb8e736-30ce-4eaf-b8e9-eeee60a68ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04e44c0d-119f-4310-ae0a-729946c0a1cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563d5487-0e02-48ad-b4d8-4430c5d76991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mlflow\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, \n",
    "    f1_score, precision_recall_curve, auc, confusion_matrix, classification_report\n",
    ")\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "814ef289-ceba-4ffe-80e6-51e972bf833c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Section for user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cee1d20-d680-42d6-8325-bca3dc41be91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split_udf(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    feature_cols: List[str],\n",
    "    numeric_cols: List[str],\n",
    "    train_end_month: str,\n",
    "    scale: bool = False\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepare data for training and testing based on COHORT_MONTH.\n",
    "    \n",
    "    Args:\n",
    "        df: Input Pandas DataFrame\n",
    "        target_col: Name of target column\n",
    "        feature_cols: List of feature column names\n",
    "        train_end_month: End month for training data (YYYY-MM format)\n",
    "        scale: Whether to apply StandardScaler to the features\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test as Pandas DataFrames/Series\n",
    "    \"\"\"\n",
    "    # Ensure input is a pandas DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    # Split data into train and test\n",
    "    train_mask = pd.to_datetime(df['COHORT_MONTH']).dt.strftime('%Y-%m') <= train_end_month\n",
    "    \n",
    "    # Create train/test splits using pandas\n",
    "    X_train = df[train_mask][feature_cols]\n",
    "    X_test = df[~train_mask][feature_cols]\n",
    "    y_train = df[train_mask][target_col]\n",
    "    y_test = df[~train_mask][target_col]\n",
    "    # Get the corresponding HCP IDs\n",
    "    bh_id_train = df[train_mask]['BH_ID']\n",
    "    bh_id_test = df[~train_mask]['BH_ID']\n",
    "\n",
    "    print(\"No. of features in input dataframe: \", len(feature_cols))\n",
    "    print(\"Positives/Negatives in train: \\n\", y_train.value_counts())\n",
    "    print(\"Positives/Negatives in test: \\n\", y_test.value_counts())\n",
    "    print(\"Shape of X_train: \", X_train.shape)\n",
    "    print(\"Shape of X_test: \", X_test.shape)\n",
    "    \n",
    "    # Scale features if scale is True\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train[numeric_cols] = pd.DataFrame(\n",
    "            scaler.fit_transform(X_train[numeric_cols]),\n",
    "            columns=numeric_cols,\n",
    "            index=X_train.index\n",
    "        )\n",
    "        X_test[numeric_cols] = pd.DataFrame(\n",
    "            scaler.transform(X_test[numeric_cols]),\n",
    "            columns=numeric_cols,\n",
    "            index=X_test.index\n",
    "        )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, bh_id_train, bh_id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44728610-1c11-4d69-a660-9f2872d4cdee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def custom_confusion_matrix(y_true, y_pred, df):\n",
    "    \"\"\"\n",
    "    Calculate confusion matrix based on unique BH_ID counts\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: true labels\n",
    "    y_pred: predicted labels\n",
    "    df: dataframe containing BH_ID column and predictions\n",
    "    \"\"\"\n",
    "    # Create a DataFrame with true labels, predictions, and BH_ID\n",
    "    results_df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'BH_ID': df['BH_ID']\n",
    "    })\n",
    "    \n",
    "    # Calculate unique BH_ID counts for each combination\n",
    "    # True Negatives (TN)\n",
    "    tn = len(results_df[(results_df['y_true'] == 0) & \n",
    "                       (results_df['y_pred'] == 0)]['BH_ID'].unique())\n",
    "    \n",
    "    # False Positives (FP)\n",
    "    fp = len(results_df[(results_df['y_true'] == 0) & \n",
    "                       (results_df['y_pred'] == 1)]['BH_ID'].unique())\n",
    "    \n",
    "    # False Negatives (FN)\n",
    "    fn = len(results_df[(results_df['y_true'] == 1) & \n",
    "                       (results_df['y_pred'] == 0)]['BH_ID'].unique())\n",
    "    \n",
    "    # True Positives (TP)\n",
    "    tp = len(results_df[(results_df['y_true'] == 1) & \n",
    "                       (results_df['y_pred'] == 1)]['BH_ID'].unique())\n",
    "    \n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    \n",
    "    # Precision\n",
    "    metrics['precision'] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    \n",
    "    # Recall (Sensitivity)\n",
    "    metrics['recall'] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # Specificity\n",
    "    metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # F1 Score\n",
    "    metrics['f1_score'] = 2 * (metrics['precision'] * metrics['recall']) / \\\n",
    "                         (metrics['precision'] + metrics['recall']) \\\n",
    "                         if (metrics['precision'] + metrics['recall']) > 0 else 0\n",
    "    \n",
    "    # Accuracy\n",
    "    metrics['accuracy'] = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Print metrics with formatted output\n",
    "    print(\"\\n=== Model Performance Metrics (Based on Unique BH_ID) ===\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {metrics['recall']:.4f}\")\n",
    "    print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "\n",
    "    return np.array([[tn, fp], [fn, tp]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7d25dcd-afc3-4192-a575-77b14b29a6df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_custom_confusion_matrix(y_test, y_pred, X_test):\n",
    "    # Calculate the modified confusion matrix\n",
    "    modified_cm = custom_confusion_matrix(y_test, y_pred, X_test)\n",
    "\n",
    "    # Plot confusion matrix with counts\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(modified_cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix (Based on Unique BH_ID counts)')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot confusion matrix with percentages\n",
    "    modified_cm_percent = modified_cm.astype('float') / modified_cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(modified_cm_percent, annot=True, fmt='.2%', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix with Percentages (Based on Unique BH_ID counts)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68e219c2-c9ef-43fb-a0fe-2fded5a55caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_prediction_probability_distribution(y_pred_proba, y_true, figsize=(12, 6), threshold=0.5):\n",
    "    \"\"\"\n",
    "    Plot the distribution of prediction probabilities for both classes\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred_proba: Predicted probabilities from the model\n",
    "    y_true: True labels\n",
    "    figsize: Size of the figure (width, height)\n",
    "    threshold: Decision threshold for classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure and axis\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Get probabilities for class 1\n",
    "    probabilities = y_pred_proba\n",
    "    \n",
    "    # Separate probabilities for actual positive and negative classes\n",
    "    prob_positive = probabilities[y_true == 1]\n",
    "    prob_negative = probabilities[y_true == 0]\n",
    "    \n",
    "    # Create the distribution plot\n",
    "    sns.kdeplot(prob_negative, label='Class 0 (Actual)', color='blue', shade=True)\n",
    "    sns.kdeplot(prob_positive, label='Class 1 (Actual)', color='red', shade=True)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Distribution of Predicted Probabilities by Actual Class', fontsize=12)\n",
    "    plt.xlabel('Predicted Probability of Class 1', fontsize=10)\n",
    "    plt.ylabel('Density', fontsize=10)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical line at the specified threshold\n",
    "    plt.axvline(x=threshold, color='green', linestyle='--', alpha=0.5, label=f'Decision Threshold ({threshold})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nProbability Distribution Statistics:\")\n",
    "    print(f\"Class 0 - Mean: {np.mean(prob_negative):.3f}, Std: {np.std(prob_negative):.3f}\")\n",
    "    print(f\"Class 1 - Mean: {np.mean(prob_positive):.3f}, Std: {np.std(prob_positive):.3f}\")\n",
    "\n",
    "# Assuming you have your model predictions stored in y_pred_proba and actual values in the dataframe\n",
    "# Replace 'your_model' with your actual model\n",
    "# y_pred_proba = your_model.predict_proba(X_test)  # If you're working with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d83355a-b6c1-4b48-8086-40c0e335b12d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_prediction_probability_histogram(y_pred_proba, y_true, bins=50, figsize=(12, 6), threshold=0.5):\n",
    "    \"\"\"\n",
    "    Plot histogram of prediction probabilities for both classes\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred_proba: Predicted probabilities from the model\n",
    "    y_true: True labels\n",
    "    bins: Number of bins for histogram\n",
    "    figsize: Size of the figure (width, height)\n",
    "    threshold: Decision threshold for classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure and axis\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Get probabilities for class 1\n",
    "    probabilities = y_pred_proba\n",
    "    \n",
    "    # Separate probabilities for actual positive and negative classes\n",
    "    prob_positive = probabilities[y_true == 1]\n",
    "    prob_negative = probabilities[y_true == 0]\n",
    "    \n",
    "    # Create histograms\n",
    "    plt.hist(prob_negative, bins=bins, alpha=0.6, color='blue', \n",
    "             label=f'Class 0 (n={len(prob_negative)})', \n",
    "             density=True)\n",
    "    plt.hist(prob_positive, bins=bins, alpha=0.6, color='red', \n",
    "             label=f'Class 1 (n={len(prob_positive)})', \n",
    "             density=True)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Distribution of Predicted Probabilities by Actual Class', fontsize=12)\n",
    "    plt.xlabel('Predicted Probability of Class 1', fontsize=10)\n",
    "    plt.ylabel('Density', fontsize=10)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical line at the specified threshold\n",
    "    plt.axvline(x=threshold, color='green', linestyle='--', alpha=0.5, \n",
    "                label=f'Decision Threshold ({threshold})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nProbability Distribution Statistics:\")\n",
    "    print(f\"Class 0 - Mean: {np.mean(prob_negative):.3f}, Std: {np.std(prob_negative):.3f}\")\n",
    "    print(f\"Class 1 - Mean: {np.mean(prob_positive):.3f}, Std: {np.std(prob_positive):.3f}\")\n",
    "    print(f\"\\nClass 0 count: {len(prob_negative)}\")\n",
    "    print(f\"Class 1 count: {len(prob_positive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bda6e2b7-c6e0-4e49-9650-2388a5ef7f98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def optimize_threshold_best_precision(y_true, y_prob):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "    best_threshold = 0.5\n",
    "    best_precision = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        \n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e232ed51-615a-44cf-b2fc-3986ab7f6739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def optimize_threshold_best_recall(y_true, y_prob):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "    best_threshold = 0.5\n",
    "    best_recall = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        \n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd89813d-ee9b-498b-b452-84f850c332b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_pred_proba, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate and print various classification metrics.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): True labels.\n",
    "    y_pred (array-like): Predicted labels.\n",
    "    y_pred_proba (array-like): Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing various classification metrics.\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'auc_roc': roc_auc_score(y_true, y_pred_proba),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "    # Calculate PR AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    metrics['auc_pr'] = auc(recall, precision)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics['TNs'] = cm[0, 0]\n",
    "    metrics['FPs'] = cm[0, 1]\n",
    "    metrics['FNs'] = cm[1, 0]\n",
    "    metrics['TPs'] = cm[1, 1]\n",
    "\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.3f}\")\n",
    "\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix with Counts')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot confusion matrix with percentages\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.2%', cmap='Blues', cbar=False, \n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix with Percentages')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot y_pred_proba histogram with respect to classes in y\n",
    "    if y_pred_proba is not None:\n",
    "        if threshold != 0.5:\n",
    "            # Create the plot with given threshold val\n",
    "            plot_prediction_probability_histogram(y_pred_proba=y_pred_proba, \n",
    "                                                  y_true=y_true, \n",
    "                                                  threshold=threshold)\n",
    "        else:\n",
    "            # Create the plot with default threshold val\n",
    "            plot_prediction_probability_histogram(y_pred_proba=y_pred_proba,\n",
    "                                                  y_true=y_true)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91ca5a63-3882-4fe4-abf2-9e70059ef848",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Start of modeling workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cf81b8-0210-4341-8583-eb34f215a918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00_config/set-up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "287c301a-8239-4b62-a664-76bcbe38cfda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Month and Date parameters for manual control\n",
    "first_month = \"2019-12\"\n",
    "last_month = \"2024-11\"\n",
    "\n",
    "train_start_month = \"2023-01\"\n",
    "train_end_month = \"2024-04\"\n",
    "test_start_month = \"2024-05\"\n",
    "test_end_month = \"2024-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0bbca16-6d71-49c9-a460-e10cd2767ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading the feature master table from Hivestore\n",
    "hcp_feats_master_w_target_sdf = spark.sql(\"SELECT * FROM jivi_new_writer_model.hcp_feats_master_w_target\")\n",
    "print(\n",
    "    \"Row count: \",\n",
    "    hcp_feats_master_w_target_sdf.count(),\n",
    "    \"Column Count: \",\n",
    "    len(hcp_feats_master_w_target_sdf.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbded0fe-6ffb-4101-b743-596ade038d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Converting Spark dataframe to Pandas dataframe\n",
    "hcp_feats_master_w_target_pdf = hcp_feats_master_w_target_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ca94fc-1c5f-400c-83a8-9a9f4aaee2ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    col for col in hcp_feats_master_w_target_pdf.columns \n",
    "    if col not in ['BH_ID', 'COHORT_MONTH', 'JIVI_NEW_WRITER_FLG']\n",
    "]\n",
    "binary_cols = ['AFFL_WI_INSN', 'AFFL_WI_JIVI_HCP_12M']\n",
    "numeric_cols = [col for col in feat_cols if col not in binary_cols]\n",
    "target_col_nm = 'JIVI_NEW_WRITER_FLG'\n",
    "print(\"Names of binary feats\", binary_cols)\n",
    "print(\"Number of features: \", len(feat_cols))\n",
    "print(\"Names of numeric feats\")\n",
    "display(pd.DataFrame(numeric_cols, columns=['continuous_feats']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d52e6548-3606-4f13-9c31-14e282aeaf05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Splitting data for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d564b743-5e38-4a3f-a710-50d0ceec0a32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create train and test dataset\n",
    "X_train, X_test, y_train, y_test, bh_id_train, bh_id_test = train_test_split_udf(\n",
    "  hcp_feats_master_w_target_pdf, \n",
    "  target_col_nm, \n",
    "  feat_cols,\n",
    "  numeric_cols,\n",
    "  train_end_month, \n",
    "  scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662b557e-5f56-4c1a-a4d5-49de45fc1cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Applying Oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf9c587e-93a4-445e-b7fa-50da2fc85571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# applying oversampling for the minority class\n",
    "ros = RandomOverSampler()\n",
    "X_train_oversampled, y_train_oversampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cb21811-f8f4-4016-9a54-f2defac34526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Positives/Negatives in dataset after oversampling: \\n\", y_train_oversampled.value_counts())\n",
    "print(\"Shape of dataset after oversampling: \", X_train_oversampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dad9de4e-a653-4b7b-bd90-42d590276127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Applying undersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a807d2-838e-4d90-96b7-6482d8760374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# applying undersampling for the majority class\n",
    "rus = RandomUnderSampler()\n",
    "X_train_undersampled, y_train_undersampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f360ab-540d-407e-b7ac-3c0a1bfb68c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Positives/Negatives in dataset after undersampling: \\n\", y_train_undersampled.value_counts())\n",
    "print(\"Shape of dataset after undersampling: \", X_train_undersampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5235b65-d628-4443-8c3b-3d4da438175e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lasso Logistic Regressions for both trained on Undersampled and Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ea53110-da9a-4558-84e4-348a17de0a05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For Ridge regression\n",
    "# logit_reg = LogisticRegression(penalty='l2', class_weight='balanced', random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3598130-62c4-4549-a316-8743bcd45b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Lasso logistic regression models\n",
    "logit_reg_undersampled = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000)\n",
    "logit_reg_oversampled = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd069b4e-4287-45ab-ab2b-8d6a1a213bc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the undersampled model\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Lasso - Undersampled\") as run:\n",
    "    mlflow.autolog()\n",
    "    logit_reg_undersampled.fit(X_train_undersampled, y_train_undersampled)\n",
    "    mlflow.sklearn.log_model(logit_reg_undersampled, \"logit_reg_undersampled\")\n",
    "    model_uri = f\"runs:/{run.info.run_id}/logit_reg_undersampled\"\n",
    "    mlflow.register_model(model_uri, \"LogisticRegressionLassoUndersampled\")\n",
    "\n",
    "# Log the oversampled model\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Lasso - Oversampled\") as run:\n",
    "    mlflow.autolog()\n",
    "    logit_reg_oversampled.fit(X_train_oversampled, y_train_oversampled)\n",
    "    mlflow.sklearn.log_model(logit_reg_oversampled, \"logit_reg_oversampled\")\n",
    "    model_uri = f\"runs:/{run.info.run_id}/logit_reg_oversampled\"\n",
    "    mlflow.register_model(model_uri, \"LogisticRegressionLassoOversampled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ef69409-e5ed-47b1-aaf6-068f8d513fb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check the performance of the model, fitted to Undersampled class balanced dataset, against the whole dataset in the TEST period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be6c989b-5f14-48d4-aae1-f704b3806347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the full test dataset\n",
    "y_pred = logit_reg_undersampled.predict(X_test)\n",
    "y_pred_proba = logit_reg_undersampled.predict_proba(X_test)[:, 1]\n",
    "\n",
    "calculate_metrics(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0161fc85-cbb3-453b-b254-f0513eb6c42b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Go ahead with logistic regression fitted to Undersampled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0205617-d77a-44ef-a261-ad6d90a5ee33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Optimize probability cut-offs for Precision and Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f481ed24-d94b-41fa-863a-c169e9c29988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred = logit_reg_undersampled.predict(X_test)\n",
    "y_pred_proba = logit_reg_undersampled.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8577a46a-c09d-429a-a9ba-9566cb422d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal threshold for PRECISION\n",
    "threshold = float(optimize_threshold_best_precision(y_test, y_pred_proba))\n",
    "print(\"Optimal probability threshold for precision: \", threshold)  \n",
    "# Make final predictions\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "# Calculate metrics\n",
    "calculate_metrics(y_test, y_pred, y_pred_proba, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdb60407-2ae7-4021-98a1-5630bb3c14f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal threshold for RECALL\n",
    "threshold = optimize_threshold_best_recall(y_test, y_pred_proba) \n",
    "print(\"Optimal probability threshold for recall: \", threshold)  \n",
    "# Make final predictions\n",
    "# y_pred = (y_pred_proba >= 0.3).astype(int)\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "# Calculate metrics\n",
    "calculate_metrics(y_test, y_pred, y_pred_proba, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef541d86-62a8-4f13-82ff-158ab7668881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Custom threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b23c5f27-3b82-4d7e-b466-5e70cf62d5a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# threshold = 0.83\n",
    "threshold = 0.95\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "# Calculate metrics\n",
    "calculate_metrics(y_test, y_pred, y_pred_proba, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10b583b3-e64d-4fb1-a402-b56627087f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Plotting confusion matrix based on unique HCP counts instead of based on number of total records in the negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2f6333c-f020-44a9-8853-1e6878b8df44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # ADDING THE PREDICTED PROBABILITIES TO THE MASTER DATAFRAME\n",
    "# hcp_feats_master_w_target_pdf['y_pred_proba'] = y_pred_proba\n",
    "# hcp_feats_master_w_target_pdf['y_pred'] = y_pred\n",
    "# display(hcp_feats_master_w_target_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7b150a8-dc99-4b34-a57d-8c0f20ebc504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba = logit_reg_undersampled.predict_proba(X_test)[:, 1]\n",
    "# threshold = 0.83\n",
    "threshold = 0.95\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f704b517-38f5-4bf1-b180-73c1c1567aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ADDING THE PREDICTED PROBABILITIES TO THE MASTER DATAFRAME\n",
    "X_test_copy = X_test.copy()\n",
    "X_test_copy['y_pred_proba'] = y_pred_proba\n",
    "X_test_copy['y_pred'] = y_pred\n",
    "X_test_copy['BH_ID'] = bh_id_test\n",
    "display(X_test_copy.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43e32755-30c0-4d8b-b2cc-663588ff3b44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db31a837-1d61-4ce3-a82f-0ad2dc86f72e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test_copy.y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ae4bb1a-db6e-44e4-9a1c-10ff2369528c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Unique HCPs in Trainset: \", len(set(bh_id_train)))\n",
    "print(\"Unique HCPs in Testset: \", len(set(bh_id_test)))\n",
    "bh_id_train_unq = set(bh_id_train)\n",
    "bh_id_test_unq = set(bh_id_test)\n",
    "common_bh_ids = bh_id_train_unq.intersection(bh_id_test_unq)\n",
    "print(\"Common HCPs in train and test: \", len(common_bh_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1a0d407-bf25-4b40-b6b3-22a2d5147739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_custom_confusion_matrix(y_test, y_pred, X_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "742ec33b-f59b-44ca-8b51-be9bd6ae4978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_precision_recall_curve(y_test, y_pred_proba):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(recall, precision, marker='.', label=f'Average Precision = {average_precision:.2f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cb6da4f-3d38-448c-a3be-905225250f5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming y_test and y_pred_proba are already defined\n",
    "plot_precision_recall_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df3bb6bb-fd89-4d8a-ac52-bb3d3ca77562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mask = hcp_feats_master_w_target_pdf.BH_ID.isin(common_bh_ids)\n",
    "hcp_feats_master_w_target_pdf_common = hcp_feats_master_w_target_pdf[mask]\n",
    "hcp_feats_master_w_target_pdf_common.JIVI_NEW_WRITER_FLG.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2378ee56-75f2-4a67-b037-0ea60f00a259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f53a240-0793-47aa-9d34-fa40f9c6e6c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d755be1f-f649-4c87-b45d-9d2af388238b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check the performance of the model, fitted to Oversampled class balanced dataset, against the whole dataset in test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4ca7f6-05eb-4fd7-b588-c35303232291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the full dataset\n",
    "y_pred = logit_reg_oversampled.predict(X_test)\n",
    "y_pred_proba = logit_reg_oversampled.predict_proba(X_test)[:, 1]\n",
    "\n",
    "calculate_metrics(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a1e1a70-4a85-4562-bf86-82792943166b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "263b939d-6639-456a-a3e1-f3878676d865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df037f29-bc44-4186-8cdc-31622a1c737b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2c84327-c461-41f7-ada6-2a2e4f8c430a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "filterBlob": "{\"filterGroups\":[],\"syncTimestamp\":1740159911782}",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# GET MODEL COEFFICIENTS OF UNDERSAMPLED DATA FITTED LOGISTIC REGRESSION\n",
    "co_eff = logit_reg_undersampled.coef_[0]\n",
    "\n",
    "# Put in DataFrame and sort by effect size\n",
    "co_eff_df = pd.DataFrame()\n",
    "co_eff_df['feature'] = feat_cols\n",
    "co_eff_df['co_eff'] = co_eff\n",
    "co_eff_df['abs_co_eff'] = np.abs(co_eff)\n",
    "co_eff_df_sorted = co_eff_df.sort_values(by='co_eff', ascending=False, inplace=False)\n",
    "display(co_eff_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83079f71-24a1-473f-ab6e-801f333c12f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SHAP feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76cccc4b-c054-41e9-ac0b-37e403e25c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the SHAP explainer\n",
    "explainer = shap.Explainer(logit_reg_undersampled, X_train)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_test)\n",
    "# shap_values = explainer(X_train)\n",
    "\n",
    "# # Plot the SHAP summary plot\n",
    "# shap.summary_plot(shap_values, X_test, feature_names=feat_cols)\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc5653fd-4896-4b31-8000-d4323b3feaf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values = explainer(X_test), \n",
    "                  features = X_undersampled.values,\n",
    "                  feature_names = X_undersampled.columns.values,\n",
    "                  plot_type='dot',\n",
    "                  max_display=15,\n",
    "                  show=False)\n",
    "plt.tight_layout(rect=[0, 0, 2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca2a88d-5c7e-425a-9e73-af168e8cce1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values = explainer(X_train), \n",
    "                  features = X_train.values,\n",
    "                  feature_names = X_train.columns.values,\n",
    "                  plot_type='bar',\n",
    "                  max_display=15,\n",
    "                  show=False)\n",
    "plt.tight_layout(rect=[0, 0, 2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2408426e-a411-49f9-9338-7d6efa57f020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize SHAP JavaScript visualization\n",
    "shap.initjs()\n",
    "\n",
    "# Select an index for the SHAP force plot\n",
    "ind = 1\n",
    "\n",
    "# Plot the SHAP force plot\n",
    "shap.force_plot(shap_values[ind], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61d5ff03-f04f-4c72-800f-d77390bdb448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# top 20 features to show importance\n",
    "max_display = 20\n",
    "\n",
    "# For linear models, use coefficients directly\n",
    "importance = np.abs(logit_reg_undersampled.coef_[0])\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feat_cols,\n",
    "    'importance': importance\n",
    "})\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    'importance', ascending=False\n",
    ").head(max_display)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(\n",
    "    range(len(feature_importance_df)),\n",
    "    feature_importance_df['importance']\n",
    ")\n",
    "plt.yticks(\n",
    "    range(len(feature_importance_df)),\n",
    "    feature_importance_df['feature']\n",
    ")\n",
    "plt.xlabel('|Coefficient|')\n",
    "plt.title('Feature Importance (Logistic Regression Coefficients)')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01_training_model_jivi_writers_explore",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
