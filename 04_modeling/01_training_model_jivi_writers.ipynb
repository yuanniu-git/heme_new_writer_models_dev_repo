{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb7944c-e4c3-4839-93fd-8f1022a025e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training binary classification model for Jivi restart writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c584d628-9c9e-42de-9d00-059ff18d4dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb8e736-30ce-4eaf-b8e9-eeee60a68ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04e44c0d-119f-4310-ae0a-729946c0a1cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563d5487-0e02-48ad-b4d8-4430c5d76991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, \n",
    "    f1_score, precision_recall_curve, auc\n",
    ")\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cf81b8-0210-4341-8583-eb34f215a918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00_config/set-up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "287c301a-8239-4b62-a664-76bcbe38cfda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Month and Date parameters for manual control\n",
    "first_month = \"2019-12\"\n",
    "last_month = \"2024-11\"\n",
    "\n",
    "train_start_month = \"2023-01\"\n",
    "train_end_month = \"2024-04\"\n",
    "test_start_month = \"2024-05\"\n",
    "test_end_month = \"2024-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0bbca16-6d71-49c9-a460-e10cd2767ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading the feature master table from Hivestore\n",
    "hcp_feats_master_w_target_sdf = spark.sql(\"SELECT * FROM jivi_new_writer_model.hcp_feats_master_w_target\")\n",
    "print(\n",
    "    \"Row count: \",\n",
    "    hcp_feats_master_w_target_sdf.count(),\n",
    "    \"Column Count: \",\n",
    "    len(hcp_feats_master_w_target_sdf.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbded0fe-6ffb-4101-b743-596ade038d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Converting Spark dataframe to Pandas dataframe\n",
    "hcp_feats_master_w_target_pdf = hcp_feats_master_w_target_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ca94fc-1c5f-400c-83a8-9a9f4aaee2ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feat_cols_nm_lst = [col for col in hcp_feats_master_w_target_pdf.columns if col not in ['BH_ID', 'COHORT_MONTH', 'JIVI_NEW_WRITER_FLG']]\n",
    "target_col_nm = 'JIVI_NEW_WRITER_FLG'\n",
    "print(\"Names of feats\", feat_cols_nm_lst)\n",
    "print(\"Number of features: \", len(feat_cols_nm_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db68d1f8-3d19-42a4-ba0a-1bcda71d17ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def prepare_data(\n",
    "#     df: pd.DataFrame,\n",
    "#     target_col: str,\n",
    "#     feature_cols: List[str],\n",
    "#     train_end_month: str = train_end_month\n",
    "# ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Prepare data for training and testing based on COHORT_MONTH.\n",
    "    \n",
    "#     Args:\n",
    "#         df: Input DataFrame\n",
    "#         target_col: Name of target column\n",
    "#         feature_cols: List of feature column names\n",
    "#         train_end_month: End month for training data (YYYY-MM format)\n",
    "    \n",
    "#     Returns:\n",
    "#         X_train, X_test, y_train, y_test arrays\n",
    "#     \"\"\"\n",
    "#     # Split data into train and test\n",
    "#     train_mask = pd.to_datetime(df['COHORT_MONTH']).dt.strftime('%Y-%m') <= train_end_month\n",
    "    \n",
    "#     X_train = df[train_mask][feature_cols].values\n",
    "#     X_test = df[~train_mask][feature_cols].values\n",
    "#     y_train = df[train_mask][target_col].values\n",
    "#     y_test = df[~train_mask][target_col].values\n",
    "    \n",
    "#     # Scale features\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec62446-0c77-41e0-b662-57cabaa6d1fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def select_features(\n",
    "#     X_train: np.ndarray,\n",
    "#     y_train: np.ndarray,\n",
    "#     feature_cols: List[str],\n",
    "#     method: str = 'rf'\n",
    "# ) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "#     \"\"\"\n",
    "#     Perform feature selection using either Random Forest or RFE.\n",
    "    \n",
    "#     Args:\n",
    "#         X_train: Training features\n",
    "#         y_train: Training target\n",
    "#         feature_cols: List of feature names\n",
    "#         method: Feature selection method ('rf' or 'rfe')\n",
    "    \n",
    "#     Returns:\n",
    "#         Selected X_train, X_test, and selected feature names\n",
    "#     \"\"\"\n",
    "#     if method == 'rf':\n",
    "#         selector = SelectFromModel(\n",
    "#             RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#             max_features=min([50, X_train.shape[1]])\n",
    "#         )\n",
    "#     else:\n",
    "#         selector = RFE(\n",
    "#             estimator=LogisticRegression(random_state=42),\n",
    "#             n_features_to_select=min([50, X_train.shape[1]])\n",
    "#         )\n",
    "    \n",
    "#     selector.fit(X_train, y_train)\n",
    "#     selected_features = [f for f, s in zip(feature_cols, selector.get_support()) if s]\n",
    "#     return X_train[:, selector.get_support()], selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d298025-20b9-437a-9d4e-fe4bf372a7db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def create_time_series_cv(\n",
    "#     X: np.ndarray,\n",
    "#     y: np.ndarray,\n",
    "#     n_splits: int = 7 # equal to number of months in test period\n",
    "# ) -> TimeSeriesSplit:\n",
    "#     \"\"\"\n",
    "#     Create time series cross-validation splits.\n",
    "    \n",
    "#     Args:\n",
    "#         X: Feature matrix\n",
    "#         y: Target vector\n",
    "#         n_splits: Number of splits for cross-validation\n",
    "    \n",
    "#     Returns:\n",
    "#         TimeSeriesSplit object\n",
    "#     \"\"\"\n",
    "#     return TimeSeriesSplit(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee72e389-73b6-495a-922c-0af84c24e392",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def train_evaluate_model(\n",
    "#     model: Any,\n",
    "#     X_train: np.ndarray,\n",
    "#     X_test: np.ndarray,\n",
    "#     y_train: np.ndarray,\n",
    "#     y_test: np.ndarray,\n",
    "#     cv: TimeSeriesSplit\n",
    "# ) -> Dict[str, float]:\n",
    "#     \"\"\"\n",
    "#     Train model and evaluate performance using multiple metrics.\n",
    "    \n",
    "#     Args:\n",
    "#         model: ML model instance\n",
    "#         X_train, X_test, y_train, y_test: Training and test data\n",
    "#         cv: Cross-validation splitter\n",
    "    \n",
    "#     Returns:\n",
    "#         Dictionary of evaluation metrics\n",
    "#     \"\"\"\n",
    "#     # Train model\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Get predictions\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     metrics = {\n",
    "#         'auc_roc': roc_auc_score(y_test, y_pred_proba),\n",
    "#         'precision': precision_score(y_test, y_pred),\n",
    "#         'recall': recall_score(y_test, y_pred),\n",
    "#         'f1': f1_score(y_test, y_pred),\n",
    "#     }\n",
    "    \n",
    "#     # Calculate PR AUC\n",
    "#     precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "#     metrics['auc_pr'] = auc(recall, precision)\n",
    "    \n",
    "#     return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b78cb8a7-a401-4f74-9e2f-b1fb02775bac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def plot_learning_curves(\n",
    "#     model: Any,\n",
    "#     X_train: np.ndarray,\n",
    "#     y_train: np.ndarray,\n",
    "#     cv: TimeSeriesSplit\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Plot learning curves for the model.\n",
    "    \n",
    "#     Args:\n",
    "#         model: ML model instance\n",
    "#         X_train: Training features\n",
    "#         y_train: Training target\n",
    "#         cv: Cross-validation splitter\n",
    "#     \"\"\"\n",
    "#     train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "#     train_scores = []\n",
    "#     val_scores = []\n",
    "    \n",
    "#     for train_idx, val_idx in cv.split(X_train):\n",
    "#         X_train_cv, X_val_cv = X_train[train_idx], X_train[val_idx]\n",
    "#         y_train_cv, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "#         for size in train_sizes:\n",
    "#             n_samples = int(len(X_train_cv) * size)\n",
    "#             model.fit(X_train_cv[:n_samples], y_train_cv[:n_samples])\n",
    "            \n",
    "#             train_score = model.score(X_train_cv[:n_samples], y_train_cv[:n_samples])\n",
    "#             val_score = model.score(X_val_cv, y_val_cv)\n",
    "            \n",
    "#             train_scores.append(train_score)\n",
    "#             val_scores.append(val_score)\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(train_sizes, np.mean(train_scores, axis=0), label='Training score')\n",
    "#     plt.plot(train_sizes, np.mean(val_scores, axis=0), label='Cross-validation score')\n",
    "#     plt.xlabel('Training set size')\n",
    "#     plt.ylabel('Score')\n",
    "#     plt.title('Learning Curves')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f15a30a-5584-45a8-a87f-6b350ff5828c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def analyze_feature_importance(\n",
    "#     model: Any,\n",
    "#     X_train: np.ndarray,\n",
    "#     feature_names: List[str]\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Analyze feature importance using SHAP values.\n",
    "    \n",
    "#     Args:\n",
    "#         model: Trained ML model\n",
    "#         X_train: Training features\n",
    "#         feature_names: List of feature names\n",
    "#     \"\"\"\n",
    "#     explainer = shap.TreeExplainer(model) if hasattr(model, 'feature_importances_') \\\n",
    "#         else shap.KernelExplainer(model.predict_proba, X_train)\n",
    "#     shap_values = explainer.shap_values(X_train)\n",
    "    \n",
    "#     if isinstance(shap_values, list):\n",
    "#         shap_values = shap_values[1]\n",
    "    \n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     shap.summary_plot(shap_values, X_train, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dc0e571-cab2-4cd6-b2ca-791cdb768ab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def run_ml_pipeline(\n",
    "#     df: pd.DataFrame,\n",
    "#     target_col: str,\n",
    "#     feature_cols: List[str]\n",
    "# ) -> Dict[str, Dict[str, float]]:\n",
    "#     \"\"\"\n",
    "#     Run the complete ML pipeline.\n",
    "    \n",
    "#     Args:\n",
    "#         df: Input DataFrame\n",
    "#         target_col: Name of target column\n",
    "#         feature_cols: List of feature column names\n",
    "    \n",
    "#     Returns:\n",
    "#         Dictionary of model performances\n",
    "#     \"\"\"\n",
    "#     # Prepare data\n",
    "#     X_train, X_test, y_train, y_test = prepare_data(df, target_col, feature_cols)\n",
    "    \n",
    "#     # Feature selection\n",
    "#     X_train_selected, selected_features = select_features(X_train, y_train, feature_cols)\n",
    "#     X_test_selected = X_test[:, [feature_cols.index(f) for f in selected_features]]\n",
    "    \n",
    "#     # Create CV splits\n",
    "#     cv = create_time_series_cv(X_train_selected, y_train)\n",
    "    \n",
    "#     # Initialize models\n",
    "#     models = {\n",
    "#         'logistic': LogisticRegression(class_weight='balanced', random_state=42),\n",
    "#         'random_forest': RandomForestClassifier(\n",
    "#             n_estimators=100, class_weight='balanced', random_state=42\n",
    "#         ),\n",
    "#         'neural_network': MLPClassifier(\n",
    "#             hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42\n",
    "#         ),\n",
    "#         'xgboost': XGBClassifier(\n",
    "#             scale_pos_weight=len(y_train)/sum(y_train), random_state=42\n",
    "#         )\n",
    "#     }\n",
    "    \n",
    "#     # Train and evaluate models\n",
    "#     results = {}\n",
    "#     for name, model in models.items():\n",
    "#         results[name] = train_evaluate_model(\n",
    "#             model, X_train_selected, X_test_selected, y_train, y_test, cv\n",
    "#         )\n",
    "        \n",
    "#         # Plot learning curves\n",
    "#         plot_learning_curves(model, X_train_selected, y_train, cv)\n",
    "        \n",
    "#         # Analyze feature importance\n",
    "#         analyze_feature_importance(model, X_train_selected, selected_features)\n",
    "    \n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc2d5603-fd66-479a-a045-05af429973a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def run_ml_pipeline(\n",
    "#     df: pd.DataFrame,\n",
    "#     target_col: str,\n",
    "#     feature_cols: List[str],\n",
    "#     use_feature_selection: bool = False,\n",
    "#     feature_selection_method: str = 'rf'\n",
    "# ) -> Dict[str, Dict[str, float]]:\n",
    "#     \"\"\"\n",
    "#     Run the complete ML pipeline.\n",
    "    \n",
    "#     Args:\n",
    "#         df: Input DataFrame\n",
    "#         target_col: Name of target column\n",
    "#         feature_cols: List of feature column names\n",
    "#         use_feature_selection: Whether to use feature selection\n",
    "#         feature_selection_method: Method for feature selection ('rf' or 'rfe')\n",
    "    \n",
    "#     Returns:\n",
    "#         Dictionary of model performances\n",
    "#     \"\"\"\n",
    "#     # Prepare data\n",
    "#     X_train, X_test, y_train, y_test = prepare_data(df, target_col, feature_cols)\n",
    "    \n",
    "#     if use_feature_selection:\n",
    "#         # Feature selection\n",
    "#         X_train, selected_features = select_features(X_train, y_train, feature_cols, method=feature_selection_method)\n",
    "#         X_test = X_test[:, [feature_cols.index(f) for f in selected_features]]\n",
    "#     else:\n",
    "#         selected_features = feature_cols\n",
    "#         X_train_selected = X_train\n",
    "#         X_test_selected = X_test\n",
    "    \n",
    "#     # Create CV splits\n",
    "#     cv = create_time_series_cv(X_train_selected, y_train)\n",
    "    \n",
    "#     # Initialize models\n",
    "#     models = {\n",
    "#         'logistic': LogisticRegression(class_weight='balanced', random_state=42),\n",
    "#         'random_forest': RandomForestClassifier(\n",
    "#             n_estimators=100, class_weight='balanced', random_state=42\n",
    "#         ),\n",
    "#         'neural_network': MLPClassifier(\n",
    "#             hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42\n",
    "#         ),\n",
    "#         'xgboost': XGBClassifier(\n",
    "#             scale_pos_weight=len(y_train)/y_train.sum(), random_state=42\n",
    "#         )\n",
    "#     }\n",
    "    \n",
    "#     # Train and evaluate models\n",
    "#     results = {}\n",
    "#     for name, model in models.items():\n",
    "#         results[name] = train_evaluate_model(\n",
    "#             model, X_train_selected, X_test_selected, y_train, y_test, cv\n",
    "#         )\n",
    "        \n",
    "#         # Plot learning curves\n",
    "#         plot_learning_curves(model, X_train_selected, y_train, cv)\n",
    "        \n",
    "#         # Analyze feature importance\n",
    "#         analyze_feature_importance(model, X_train_selected, selected_features)\n",
    "    \n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c8c2fe2-96c9-485f-a90b-442afd8a75a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Usage\n",
    "# results = run_ml_pipeline(\n",
    "#     df=hcp_feats_master_w_target_pdf,\n",
    "#     target_col=target_col_nm,\n",
    "#     feature_cols=feat_cols_nm_lst,\n",
    "#     use_feature_selection=False,  # Set to False if you don't want to use feature selection\n",
    "#     feature_selection_method='rf'  # 'rf' or 'rfe'\n",
    "# )\n",
    "\n",
    "# # Print results\n",
    "# for model_name, metrics in results.items():\n",
    "#     print(f\"\\nResults for {model_name}:\")\n",
    "#     for metric_name, value in metrics.items():\n",
    "#         print(f\"{metric_name}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b832e38f-9316-4c43-b8da-9747637673d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Usage\n",
    "# results = run_ml_pipeline(\n",
    "#     df = hcp_feats_master_w_target_pdf,\n",
    "#     target_col = target_col_nm,\n",
    "#     feature_cols = feat_cols_nm_lst\n",
    "# )\n",
    "\n",
    "# # Print results\n",
    "# for model_name, metrics in results.items():\n",
    "#     print(f\"\\nResults for {model_name}:\")\n",
    "#     for metric_name, value in metrics.items():\n",
    "#         print(f\"{metric_name}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7368c07-197d-4d32-8ecc-543f216178d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a807d2-838e-4d90-96b7-6482d8760374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd0ff324-fadf-410b-a91b-fe10f04091fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, \n",
    "    f1_score, precision_recall_curve, auc\n",
    ")\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def prepare_data(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    feature_cols: List[str],\n",
    "    train_end_date: str = '2024-04'\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepare data for training and testing based on COHORT_MONTH.\n",
    "    \n",
    "    Args:\n",
    "        df: Input Pandas DataFrame\n",
    "        target_col: Name of target column\n",
    "        feature_cols: List of feature column names\n",
    "        train_end_date: End date for training data (YYYY-MM format)\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test as Pandas DataFrames/Series\n",
    "    \"\"\"\n",
    "    # Ensure input is a pandas DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    # Convert COHORT_MONTH to datetime if it's not already\n",
    "    df['COHORT_MONTH'] = pd.to_datetime(df['COHORT_MONTH'])\n",
    "    \n",
    "    # Split data into train and test\n",
    "    train_mask = df['COHORT_MONTH'].dt.strftime('%Y-%m') <= train_end_date\n",
    "    \n",
    "    # Create train/test splits using pandas\n",
    "    X_train = df[train_mask][feature_cols]\n",
    "    X_test = df[~train_mask][feature_cols]\n",
    "    y_train = df[train_mask][target_col]\n",
    "    y_test = df[~train_mask][target_col]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=feature_cols,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test),\n",
    "        columns=feature_cols,\n",
    "        index=X_test.index\n",
    "    )\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def select_features(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    method: str = 'rf'\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Perform feature selection using either Random Forest or RFE.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features DataFrame\n",
    "        y_train: Training target Series\n",
    "        method: Feature selection method ('rf' or 'rfe')\n",
    "    \n",
    "    Returns:\n",
    "        Selected features DataFrame and list of selected feature names\n",
    "    \"\"\"\n",
    "    if method == 'rf':\n",
    "        selector = SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            max_features=min(50, X_train.shape[1])\n",
    "        )\n",
    "    else:\n",
    "        selector = RFE(\n",
    "            estimator=LogisticRegression(random_state=42),\n",
    "            n_features_to_select=min(50, X_train.shape[1])\n",
    "        )\n",
    "    \n",
    "    selector.fit(X_train, y_train)\n",
    "    selected_features = X_train.columns[selector.get_support()].tolist()\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    \n",
    "    return X_train_selected, selected_features\n",
    "\n",
    "def create_time_series_cv(\n",
    "    X: pd.DataFrame,\n",
    "    n_splits: int = 5\n",
    ") -> TimeSeriesSplit:\n",
    "    \"\"\"\n",
    "    Create time series cross-validation splits.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature DataFrame\n",
    "        n_splits: Number of splits for cross-validation\n",
    "    \n",
    "    Returns:\n",
    "        TimeSeriesSplit object\n",
    "    \"\"\"\n",
    "    return TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "def train_evaluate_model(\n",
    "    model: Any,\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    cv: TimeSeriesSplit\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Train model and evaluate performance using multiple metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: ML model instance\n",
    "        X_train, X_test: Training and test DataFrames\n",
    "        y_train, y_test: Training and test Series\n",
    "        cv: Cross-validation splitter\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'auc_roc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    # Calculate PR AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    metrics['auc_pr'] = auc(recall, precision)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_learning_curves(\n",
    "    model: Any,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    cv: TimeSeriesSplit\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot learning curves for the model.\n",
    "    \n",
    "    Args:\n",
    "        model: ML model instance\n",
    "        X_train: Training features DataFrame\n",
    "        y_train: Training target Series\n",
    "        cv: Cross-validation splitter\n",
    "    \"\"\"\n",
    "    train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "    train_scores_list = []\n",
    "    val_scores_list = []\n",
    "    \n",
    "    # Convert train_sizes to actual numbers of samples\n",
    "    n_samples = len(X_train)\n",
    "    train_sizes_abs = [int(n * n_samples) for n in train_sizes]\n",
    "    \n",
    "    # For each CV split\n",
    "    for train_idx, val_idx in cv.split(X_train):\n",
    "        X_train_cv = X_train.iloc[train_idx]\n",
    "        X_val_cv = X_train.iloc[val_idx]\n",
    "        y_train_cv = y_train.iloc[train_idx]\n",
    "        y_val_cv = y_train.iloc[val_idx]\n",
    "        \n",
    "        train_scores_split = []\n",
    "        val_scores_split = []\n",
    "        \n",
    "        # For each training size\n",
    "        for train_size in train_sizes_abs:\n",
    "            # Fit model on subset of training data\n",
    "            model_clone = clone(model)  # Create a fresh clone of the model\n",
    "            X_subset = X_train_cv.iloc[:train_size]\n",
    "            y_subset = y_train_cv.iloc[:train_size]\n",
    "            \n",
    "            model_clone.fit(X_subset, y_subset)\n",
    "            \n",
    "            # Calculate scores\n",
    "            train_score = model_clone.score(X_subset, y_subset)\n",
    "            val_score = model_clone.score(X_val_cv, y_val_cv)\n",
    "            \n",
    "            train_scores_split.append(train_score)\n",
    "            val_scores_split.append(val_score)\n",
    "        \n",
    "        train_scores_list.append(train_scores_split)\n",
    "        val_scores_list.append(val_scores_split)\n",
    "    \n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    train_scores = np.array(train_scores_list)\n",
    "    val_scores = np.array(val_scores_list)\n",
    "    \n",
    "    # Calculate means and standard deviations\n",
    "    train_mean = np.mean(train_scores, axis=0)\n",
    "    train_std = np.std(train_scores, axis=0)\n",
    "    val_mean = np.mean(val_scores, axis=0)\n",
    "    val_std = np.std(val_scores, axis=0)\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.grid()\n",
    "    \n",
    "    # Plot training scores\n",
    "    plt.fill_between(train_sizes, \n",
    "                    train_mean - train_std,\n",
    "                    train_mean + train_std, \n",
    "                    alpha=0.1,\n",
    "                    color=\"r\")\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    \n",
    "    # Plot cross-validation scores\n",
    "    plt.fill_between(train_sizes, \n",
    "                    val_mean - val_std,\n",
    "                    val_mean + val_std, \n",
    "                    alpha=0.1, \n",
    "                    color=\"g\")\n",
    "    plt.plot(train_sizes, val_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    \n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "def analyze_feature_importance(\n",
    "    model: Any,\n",
    "    X_train: pd.DataFrame\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Analyze feature importance using SHAP values.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained ML model\n",
    "        X_train: Training features DataFrame\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(model) if hasattr(model, 'feature_importances_') \\\n",
    "        else shap.KernelExplainer(model.predict_proba, X_train)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.summary_plot(shap_values, X_train)\n",
    "\n",
    "def run_ml_pipeline(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    feature_cols: List[str],\n",
    "    use_feature_selection: bool = False,\n",
    "    feature_selection_method: str = 'rf'\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Run the complete ML pipeline with optional feature selection.\n",
    "    \n",
    "    Args:\n",
    "        df: Input Pandas DataFrame\n",
    "        target_col: Name of target column\n",
    "        feature_cols: List of feature column names\n",
    "        use_feature_selection: Whether to use feature selection (default: False)\n",
    "        feature_selection_method: Method for feature selection ('rf' or 'rfe')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of model performances\n",
    "    \"\"\"\n",
    "    # Ensure input is a pandas DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test = prepare_data(df, target_col, feature_cols)\n",
    "    \n",
    "    # Feature selection (if enabled)\n",
    "    if use_feature_selection:\n",
    "        print(\"\\nPerforming feature selection...\")\n",
    "        X_train_final, selected_features = select_features(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            method=feature_selection_method\n",
    "        )\n",
    "        X_test_final = X_test[selected_features]\n",
    "        print(f\"Selected {len(selected_features)} features\")\n",
    "        print(\"Selected features:\", selected_features)\n",
    "    else:\n",
    "        X_train_final = X_train\n",
    "        X_test_final = X_test\n",
    "        selected_features = feature_cols\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv = create_time_series_cv(X_train_final)\n",
    "    \n",
    "    # Calculate class weight properly for pandas Series\n",
    "    n_samples = len(y_train)\n",
    "    n_positives = y_train.sum()\n",
    "    class_weight = n_samples / (2 * n_positives)  # adjusted class weight calculation\n",
    "    \n",
    "    # Initialize models with class weights\n",
    "    models = {\n",
    "        'logistic': LogisticRegression(\n",
    "            class_weight='balanced', \n",
    "            random_state=42,\n",
    "            max_iter=1000\n",
    "        ),\n",
    "        'random_forest': RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            class_weight='balanced', \n",
    "            random_state=42\n",
    "        ),\n",
    "        'neural_network': MLPClassifier(\n",
    "            hidden_layer_sizes=(100, 50), \n",
    "            max_iter=1000, \n",
    "            random_state=42\n",
    "        ),\n",
    "        'xgboost': XGBClassifier(\n",
    "            scale_pos_weight=class_weight, \n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        results[name] = train_evaluate_model(\n",
    "            model, \n",
    "            X_train_final, \n",
    "            X_test_final, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            cv\n",
    "        )\n",
    "        \n",
    "        print(f\"Plotting learning curves for {name}...\")\n",
    "        plot_learning_curves(model, X_train_final, y_train, cv)\n",
    "        \n",
    "        print(f\"Analyzing feature importance for {name}...\")\n",
    "        analyze_feature_importance(model, X_train_final)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"\\nMetrics for {name}:\")\n",
    "        for metric_name, value in results[name].items():\n",
    "            print(f\"{metric_name}: {value:.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d488ee5c-ace2-450d-9c85-caadfb171abf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "results = run_ml_pipeline(\n",
    "    df=hcp_feats_master_w_target_pdf,\n",
    "    target_col=target_col_nm,\n",
    "    feature_cols=feat_cols_nm_lst\n",
    ")\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nResults for {model_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6f360ab-540d-407e-b7ac-3c0a1bfb68c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01_training_model_jivi_writers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
