{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af466ea2-2cb1-4bcd-9758-5f69d8c24295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "739ff07e-f185-491e-b3dd-bfc0f40d7a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_new_to_drug(data, drg_nm, drg_nm_col, start_date, date_col, id_col,lookback_period):\n",
    "    \"\"\"\n",
    "    Calculate the monthly count of 'New-to-Drug' Healthcare Providers (HCPs) for a specific drug.\n",
    "\n",
    "    Parameters:\n",
    "    data (DataFrame): The input data containing drug prescription records.\n",
    "    drg_nm (str): The name of the drug to analyze.\n",
    "    drg_nm_col (str): The column name in the data that contains drug names.\n",
    "    start_date (str): The start date of the study period in 'YYYY-MM-DD' format.\n",
    "    date_col (str): The column name in the data that contains prescription dates.\n",
    "    id_col (str): The column name in the data that contains patient IDs or HCP ids.\n",
    "    lookback_period (numeric): The number of years to look back from the study period.\n",
    "\n",
    "    Returns:\n",
    "    report_df: A DataFrame with the monthly count of 'New-to-Drug' and existing patients/HCPs.\n",
    "    new_to_drg_pat (list): A list of patient IDs or HCP IDs who are 'NEW' to the drug.\n",
    "    \"\"\"\n",
    "    # Convert date_col to datetime\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    data = data.sort_values(by=[id_col, date_col])\n",
    "\n",
    "    # Filter data for drug prescriptions within the study period and keep the first RX date\n",
    "    first_rx = data[(data[drg_nm_col] == drg_nm) &\n",
    "                             (data[date_col] >= pd.to_datetime(start_date)) & \n",
    "                             (data[date_col] <= data[date_col].max())].drop_duplicates(subset=id_col, keep='first')\n",
    "    first_rx.rename(columns={date_col:'Index_date'}, inplace=True)\n",
    "    first_rx['Look_back_start_date'] = first_rx['Index_date'] - pd.DateOffset(years = lookback_period)\n",
    "\n",
    "   \n",
    "\n",
    "    # Filter data for drug prescriptions in the 24 months prior to the study period\n",
    "\n",
    "    df_rx = data[(data[drg_nm_col] == drg_nm)][[id_col, date_col]].drop_duplicates()\n",
    "    \n",
    "    # For each patient/hcp in the study period, find if there are prior prescriptions in the lookback period\n",
    "    first_rx_wi_prev = pd.merge(first_rx, df_rx, on = [id_col], how = 'left')\n",
    "\n",
    "    # Identify patients who were prescribed with the drug in the study period\n",
    "    pat_list = first_rx[id_col].unique().tolist()\n",
    "    \n",
    "    #Filter for patients who have been prescribed the drug in the lookback period\n",
    "    existing_pat_df = first_rx_wi_prev.loc[\n",
    "        (first_rx_wi_prev[date_col] >= first_rx_wi_prev['Look_back_start_date']) & \n",
    "        (first_rx_wi_prev[date_col] < first_rx_wi_prev['Index_date'])]\n",
    "    \n",
    "     # Identify patients/hcps who were prescribed with the drug in the lookback period\n",
    "    existing_pat_list = existing_pat_df[id_col].unique().tolist()\n",
    "\n",
    "    # Identify HCPs who prescribed the drug in the prior period\n",
    "    #prescribers_prior_period = prior_period_data[hcp_id_col].unique()\n",
    "\n",
    "    # Identify 'New-to-Brand' Patients/HCPs\n",
    "    new_to_drg_pat = set(pat_list) - set(existing_pat_list)\n",
    "\n",
    "    # Filter study period data for 'New-to-Brand' Patients/HCPs\n",
    "    new_to_drg_data = first_rx[first_rx[id_col].isin(new_to_drg_pat)]\n",
    "    \n",
    "    # Calculate monthly count of 'New-to-Drug' Patients/HCPs\n",
    "    new_to_drg_data['YR-MO'] = new_to_drg_data['Index_date'].dt.strftime('%Y-%m')\n",
    "    monthly_new_to_drgs = new_to_drg_data.groupby('YR-MO')[id_col].nunique().reset_index()\n",
    "    monthly_new_to_drgs = monthly_new_to_drgs.sort_values('YR-MO', ascending=True)\n",
    "\n",
    "    # calculate monthly count of existing patients/hcps\n",
    "    existing_pat_df['YR-MO'] = existing_pat_df['Index_date'].dt.strftime('%Y-%m')\n",
    "    monthly_existing = existing_pat_df.groupby('YR-MO')[id_col].nunique().reset_index()\n",
    "    monthly_existing = monthly_existing.sort_values('YR-MO', ascending=True)\n",
    "\n",
    "    report_df = pd.merge(monthly_new_to_drgs, monthly_existing, on = 'YR-MO', how = 'outer', suffixes=('_new', '_exist'))\n",
    "    report_df['new_plus_exist'] = report_df.sum(axis=1)\n",
    "\n",
    "    # Calculate overall count of 'New-to-Drug' Patients/HCPs\n",
    "    overall_new_to_drg = new_to_drg_data[id_col].nunique()\n",
    "    total_count_study_period = first_rx[id_col].nunique()\n",
    "\n",
    "    # Print totals\n",
    "    print(\"\")\n",
    "    print(\"Count of New-to-\", drg_nm, \" Patients/HCPs in study period: \", overall_new_to_drg)\n",
    "    print(\"Total number of Patients/HCPs who were prescribed with\", drg_nm, \" during study period: \", total_count_study_period)\n",
    "    print(\"\")\n",
    "    return report_df, new_to_drg_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a563c018-17a0-43b0-a7d9-8ee7810dd851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_monthly_iu_total(df, drug_name = None):\n",
    "    \"\"\"\n",
    "    Calculate the total IU per month for a specified drug or for all drugs if no drug name is provided.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing the data.\n",
    "    drug_name (str, optional): The name of the drug to filter the data. If None, calculates for all drugs.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with columns 'YR-MO' and 'Total_IU' representing the total IU per month.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the specified drug\n",
    "    filtered_df = df if drug_name is None else df.query(\"PRD_NM == @drug_name\")\n",
    "    \n",
    "    # Convert the 'SHP_DT' column to datetime\n",
    "    filtered_df['SHP_DT'] = pd.to_datetime(filtered_df['SHP_DT'])\n",
    "    # Extract the year-month\n",
    "    filtered_df['YR-MO'] = filtered_df['SHP_DT'].dt.strftime('%Y-%m')\n",
    "    \n",
    "    # Group by month and sum the 'IU' column\n",
    "    monthly_iu_sum = filtered_df.groupby('YR-MO')['IU'].sum().reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    monthly_iu_sum.columns = ['YR-MO', 'Total_IU']\n",
    "    \n",
    "    return monthly_iu_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77269858-a52b-4703-ba64-0150cf125913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def pandas_data_profiler(df):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of null values, number of unique values, and top 3 most frequent values for each column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input Pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with columns 'Column_Name', 'Null_Percentage', 'Unique_Values', and 'Top_3_Values' containing the respective statistics for each column in the input DataFrame.\n",
    "    \"\"\"\n",
    "    null_percentage = df.isnull().mean() * 100\n",
    "    unique_values = df.nunique()\n",
    "    top_3_values = df.apply(lambda x: x.value_counts().index[:3].tolist() if x.nunique() > 0 else [])\n",
    "    result_df = pd.DataFrame({\n",
    "        'Column_Name': df.columns,\n",
    "        'Null_Percentage': null_percentage,\n",
    "        'Unique_Values': unique_values,\n",
    "        'Top_3_Values': top_3_values\n",
    "    }).reset_index(drop=True)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# result_df = pandas_data_profiler(pandas_df)\n",
    "# display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15ac7977-414a-4fe6-a58a-96ec55179dbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def spark_data_profiler(df):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of null values, number of unique values, and top 3 most frequent values for each column in a Spark DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input Spark DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame with columns 'Column_Name', 'Null_Percentage', 'Unique_Values', and 'Top_3_Values' containing the respective statistics for each column in the input DataFrame.\n",
    "    \"\"\"\n",
    "    # Calculate null percentage\n",
    "    null_percentage = df.select([\n",
    "        (F.count(F.when(F.col(c).isNull(), c)) / F.count(F.lit(1)) * 100).alias(c) for c in df.columns\n",
    "    ]).collect()[0].asDict()\n",
    "\n",
    "    # Calculate unique values\n",
    "    unique_values = df.agg(*[F.countDistinct(c).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "\n",
    "    # Calculate top 3 values excluding nulls\n",
    "    top_3_values = {}\n",
    "    for c in df.columns:\n",
    "        top_3_values[c] = df.filter(F.col(c).isNotNull()) \\\n",
    "                            .groupBy(c) \\\n",
    "                            .count() \\\n",
    "                            .orderBy(F.desc(\"count\")) \\\n",
    "                            .limit(3) \\\n",
    "                            .select(c) \\\n",
    "                            .rdd \\\n",
    "                            .flatMap(lambda x: x) \\\n",
    "                            .collect()\n",
    "\n",
    "    # Create result DataFrame\n",
    "    result_df = spark.createDataFrame([\n",
    "        (col, null_percentage[col], unique_values[col], top_3_values[col]) for col in df.columns\n",
    "    ], [\"Column_Name\", \"Null_Percentage\", \"Unique_Values\", \"Top_3_Values\"])\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Example usage\n",
    "# result_df = spark_data_profiler(spark_df)\n",
    "# display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a72aff9-2a6f-4548-8cc3-4307264dbd9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def calculate_unique_drugs_by_class(df, months):\n",
    "#     \"\"\"\n",
    "#     Calculate unique drug by class (prescribed) counts for each BH_ID based on PRD_GRP_NM column over the past specified months.\n",
    "\n",
    "#     Parameters:\n",
    "#     df (pd.DataFrame): Input DataFrame containing columns 'BH_ID', 'PRD_GRP_NM', and 'SHP_DT'.\n",
    "#     months (int): Number of months to look back for calculating unique drug counts.\n",
    "\n",
    "#     Returns:\n",
    "#     pd.DataFrame: DataFrame with unique drug counts for each BH_ID.\n",
    "#     \"\"\"\n",
    "#     # Convert SHP_DT to datetime\n",
    "#     # df['SHP_YYYY_MM'] = df['SHP_YR_MO']\n",
    "    \n",
    "#     # Get unique values in PRD_GRP_NM\n",
    "#     unique_drg_classes = df['PRD_GRP_NM'].unique()\n",
    "    \n",
    "#     def unique_drugs_count(group, months):\n",
    "#         \"\"\"\n",
    "#         Calculate the number of unique drug classes prescribed within the past specified months for a given group.\n",
    "\n",
    "#         Parameters:\n",
    "#         group (pd.DataFrame): Grouped DataFrame.\n",
    "#         months (int): Number of months to look back.\n",
    "\n",
    "#         Returns:\n",
    "#         int: Number of unique drugs.\n",
    "#         \"\"\"\n",
    "#         end_date = group['SHP_YYYY_MM'].max()\n",
    "#         start_date = end_date - pd.DateOffset(months=months)\n",
    "#         filtered_group = group[(group['SHP_YYYY_MM'] >= start_date) & (group['SHP_YYYY_MM'] <= end_date)]\n",
    "#         return filtered_group['PRD_NM'].nunique()\n",
    "    \n",
    "#     def calculate_group_features(group):\n",
    "#         \"\"\"\n",
    "#         Calculate unique drug classes (prescribed) counts for each unique PRD_GRP_NM value within the past specified months for a given group.\n",
    "\n",
    "#         Parameters:\n",
    "#         group (pd.DataFrame): Grouped DataFrame.\n",
    "\n",
    "#         Returns:\n",
    "#         pd.Series: Series with unique drug counts for each unique PRD_GRP_NM value.\n",
    "#         \"\"\"\n",
    "#         features = {}\n",
    "#         for drg_class in unique_drg_classes:\n",
    "#             feature_name = f'{drg_class}_UNIQUE_DRUGS_{months}_MTH'\n",
    "#             features[feature_name] = unique_drugs_count(group[group['PRD_GRP_NM'] == drg_class], months)\n",
    "#         return pd.Series(features)\n",
    "    \n",
    "#     # Calculate features for each BH_ID\n",
    "#     # features = df.groupby('BH_ID').apply(calculate_group_features).reset_index()\n",
    "#     features = df.groupby('BH_ID', 'SHP_YR_MO').apply(calculate_group_features).reset_index()\n",
    "#     return features"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "helper_functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
